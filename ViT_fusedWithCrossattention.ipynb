{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aoQtCATGVwmW"
      },
      "source": [
        "# Using ViT for melspectrogram of audio samples and the associated person face fused using cross-Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovK3NgDfVyfl",
        "outputId": "3e5e2091-74b4-41b8-c6b8-d7c55c5fcca7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/DLOI_Project\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import librosa, librosa.display\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Activation, Reshape, Conv2DTranspose, Dropout\n",
        "from tensorflow.keras.layers import Reshape, MaxPooling2D, Softmax\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from IPython import display\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd 'drive/MyDrive/DLOI_Project'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ahudAL4ZQzAb"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sadly the dataset is not available anymore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na30llz-WJwk",
        "outputId": "f45670b1-f262-4c45-eda4-4dfc1a04a39b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Person :\n",
            "(950,)\n",
            "(2850,)\n",
            "(950,)\n",
            "Audio :\n",
            "(950, 56000)\n",
            "(2850, 56000)\n",
            "(950, 56000)\n",
            "Frame :\n",
            "(950, 224, 224, 3)\n",
            "(2850, 224, 224, 3)\n",
            "(950, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "path_person_test='dataset/person_test.npy'\n",
        "path_person_train='dataset/person_train.npy'\n",
        "path_person_val='dataset/person_val.npy'\n",
        "\n",
        "\n",
        "path_audioTrs_test='dataset/audioTrs_test.npy'\n",
        "path_audioTrs_train='dataset/audioTrs_train.npy'\n",
        "path_audioTrs_val='dataset/audioTrs_val.npy'\n",
        "\n",
        "path_imgFrames_test='dataset/imgFrames_test.npy'\n",
        "path_imgFrames_train='dataset/imgFrames_train.npy'\n",
        "path_imgFrames_val='dataset/imgFrames_val.npy'\n",
        "\n",
        "\n",
        "person_test = np.load(path_person_test, mmap_mode='r')\n",
        "person_train = np.load(path_person_train, mmap_mode='r')\n",
        "person_val = np.load(path_person_val, mmap_mode='r')\n",
        "\n",
        "audioTrs_test = np.load(path_audioTrs_test, mmap_mode='r')\n",
        "audioTrs_train = np.load(path_audioTrs_train, mmap_mode='r')\n",
        "audioTrs_val = np.load(path_audioTrs_val, mmap_mode='r')\n",
        "\n",
        "imgFrames_test = np.load(path_imgFrames_test, mmap_mode='r')\n",
        "imgFrames_train = np.load(path_imgFrames_train, mmap_mode='r')\n",
        "imgFrames_val = np.load(path_imgFrames_val, mmap_mode='r')\n",
        "\n",
        "\n",
        "print('Person :')\n",
        "print(np.shape(person_test)) \n",
        "print(np.shape(person_train)) \n",
        "print(np.shape(person_val)) \n",
        "\n",
        "print('Audio :')\n",
        "print(np.shape(audioTrs_test)) \n",
        "print(np.shape(audioTrs_train)) \n",
        "print(np.shape(audioTrs_val)) \n",
        "\n",
        "print('Frame :')\n",
        "print(np.shape(imgFrames_test)) \n",
        "print(np.shape(imgFrames_train)) \n",
        "print(np.shape(imgFrames_val)) \n",
        "\n",
        "nb_img_train, input_size, input_size, nb_channel = np.shape(imgFrames_train)\n",
        "\n",
        "\n",
        "download_audio_images = True\n",
        "\n",
        "if download_audio_images:\n",
        "  S_DB_val_path='audio/AudioImages_Val.npy'\n",
        "  S_DB_path='audio/AudioImages_Train.npy'\n",
        "  S_DB_test_path='audio/AudioImages_Test.npy'\n",
        "\n",
        "  S_DB_val = abs(np.load(S_DB_val_path, mmap_mode='r'))\n",
        "  S_DB_test = abs(np.load(S_DB_test_path, mmap_mode='r'))\n",
        "  S_DB = abs(np.load(S_DB_path, mmap_mode='r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_T8OqClbU-z",
        "outputId": "ba5068fd-ff6f-4cb9-db72-2862e5fa93bd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Person GT:\n",
            "(950,)\n",
            "(2850,)\n",
            "(950,)\n"
          ]
        }
      ],
      "source": [
        "# Normalization\n",
        "def NormalizeData(data):\n",
        "    return 2*((data - np.min(data)) / (np.max(data) - np.min(data)))-1\n",
        "\n",
        "def DenormalizeData(data):\n",
        "    return (256*((data+1)/2)).astype(int)\n",
        "\n",
        "GT = list(np.unique(person_train))\n",
        "new_id = [i for i in range(49)]\n",
        "id_dict = {}\n",
        "for k in range(len(GT)):\n",
        "  id_dict[GT[k]] = new_id[k]\n",
        "\n",
        "nb_class=49\n",
        "\n",
        "person_train_GT = []\n",
        "for i in range(person_train.shape[0]):\n",
        "  person_train_GT.append(id_dict[person_train[i]]) \n",
        "person_train_GT = np.stack(person_train_GT)\n",
        "output_train_class_onehot = tf.keras.utils.to_categorical(person_train_GT, nb_class)  # create one-hot encoded class\n",
        "\n",
        "person_val_GT = []\n",
        "for i in range(person_val.shape[0]):\n",
        "  person_val_GT.append(id_dict[person_val[i]]) \n",
        "person_val_GT = np.stack(person_val_GT)\n",
        "output_val_class_onehot = tf.keras.utils.to_categorical(person_val_GT, nb_class)  # create one-hot encoded class\n",
        "\n",
        "person_test_GT = []\n",
        "for i in range(person_test.shape[0]):\n",
        "  person_test_GT.append(id_dict[person_test[i]]) \n",
        "person_test_GT = np.stack(person_test_GT)\n",
        "output_test_class_onehot = tf.keras.utils.to_categorical(person_test_GT, nb_class)  # create one-hot encoded class\n",
        "   \n",
        "print('Person GT:')\n",
        "print(np.shape(person_test_GT)) \n",
        "print(np.shape(person_train_GT)) \n",
        "print(np.shape(person_val_GT)) \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oi8KzCkD2VCX"
      },
      "source": [
        "## Reshape audio file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zld2QMNScjec",
        "outputId": "121b656d-f3ba-4494-a32f-12c1698aa2a5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio :\n",
            "(950, 56000)\n",
            "(2850, 56000)\n",
            "(950, 56000)\n"
          ]
        }
      ],
      "source": [
        "print('Audio :')\n",
        "print(np.shape(audioTrs_test)) \n",
        "print(np.shape(audioTrs_train)) \n",
        "print(np.shape(audioTrs_val)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3mWtSt_tuBZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def time_shift(aud, GT, shift_limit, nbr_augment):\n",
        "  rolled = []\n",
        "  rolled_GT = []\n",
        "  for k in range(aud.shape[0]):\n",
        "    rolled.append(aud[k])\n",
        "    rolled_GT.append(GT[k])\n",
        "    for i in range(nbr_augment):\n",
        "      shift_rnd = random.random()\n",
        "      if i == 0:\n",
        "        shift_rnd = - shift_rnd\n",
        "      rolled.append(np.roll(aud[k], shift=int(shift_rnd * shift_limit)))# * aud.shape[0])))\n",
        "      rolled_GT.append(np.roll(GT[k], shift=int(shift_rnd * shift_limit)))# * GT.shape[0])))\n",
        "    \n",
        "  rolled = np.stack(rolled)\n",
        "  rolled_GT = np.stack(rolled_GT)\n",
        "\n",
        "  rolled = rolled#+np.random.normal(0,0.005,(rolled.shape[0],rolled.shape[1]))\n",
        "\n",
        "  return rolled, rolled_GT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTbUoAfztwBe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_aug,train_aug_GT = time_shift(audioTrs_train[:],person_train_GT[:] , 2000, 2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLKbhThxb0GL",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "output_train_class_onehot_aug = tf.keras.utils.to_categorical(train_aug_GT, nb_class)  # create one-hot encoded class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "Kb-NzRxUwsUn",
        "outputId": "6a5f3e61-3458-4eaf-c034-25d1786197e1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial audio shape\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3gU5fbHvycJCS00E4okGEronYgKgkgREJVrR6+K7ce1Xr161Sher1ixXOz3CupVroqIFEFBqYICUhJaIHQIEEoC0mtI8v7+2Nlkdndmd2ZnZmd29nyeJ0+mvDvvO7vvnDnvec97DgkhwDAMw7ifOLsbwDAMw0QGFvgMwzAxAgt8hmGYGIEFPsMwTIzAAp9hGCZGSLC7AWqkpKSIjIwMu5vBMAwTVeTm5h4SQqQqnXOswM/IyEBOTo7dzWAYhokqiGiX2jk26TAMw8QILPAZhmFiBBb4DMMwMQILfIZhmBiBBT7DMEyMwAKfYRgmRmCBzzAMEyOwwGcYhtHJyoLD2FJ0wu5m6MaxC68YhmGcys0f/w4AKBg9xOaW6IM1fIZhmBiBBT7DMEyMwAKfYRgmRmCBzzAMEyOwwGcYhokRWOAzDMPECCzwGYZhYgQW+AzDMDECC3yGYZgYgQU+wzBMjMACn2EYJkZggc8wDBMjsMBnGIaJEUwR+EQ0iIg2E9E2IspWOP8AEeUR0RoiWkxEbc2ol2EYhtGOYYFPRPEAPgIwGEBbALcpCPQJQogOQojOAN4EMMZovQzDMIw+zNDwuwPYJoTYIYQoATARwFB5ASHEcdluDQDChHoZhmEYHZiRAKUxgD2y/UIAl/gXIqKHATwBIBFAX6ULEdEIACMAoEmTJiY0jWEYhvESsUlbIcRHQojmAJ4B8LxKmXFCiCwhRFZqamqkmsYwDBMTmCHw9wJIl+2nScfUmAjgTybUyzAMw+jADIG/EkAmETUlokQAwwDMkBcgokzZ7hAAW02ol2EYhtGBYYEvhCgF8AiA2QA2ApgkhNhARC8R0XVSsUeIaAMRrYHHjj/caL0MwzBO4sTZ83jj5004X1Zud1NUMWPSFkKIWQBm+R17Qbb9mBn1MAzDOJW3Z2/G+N93oWlKDdySlR76AzbAK20ZhmFM4FypR7MvK3eu1zkLfAYAsPuP09hWfMLuZjAMYyGmmHSY6Kf3W78AAApGD7G5JQwT3eTvOx66kE2whs8wDGMCQrLkfLlsFzKyZzpS8LPAZxiGMUB5ucDmA4Hm0K+W77KhNcFhkw7DMIwB/rNoO96avRltG9WyuykhYQ2fYRjGAGv2HAUA7D92xuaWhIYFPsOEwedLdqLDP2fb3QzGBtTcLp3rjFkJC3yGCYNRP+TjxLlSu5vB2EDz53zWmFZM1vqjdFwIgZ/X70e5Tb76LPAZhmFMgPz2V+8+gqmrCiv2y8sFrvlgMR74ahW+XrE7so2TYIHPMAwTJnLzzpHT533ObTpwAk9MWlux//nSAmyQXDWLj5+NTAP9YIHPMAyjgBAiZJiE5s/NwvGz54OW8fLyj/lmNMsQLPAZRid/nDxndxOYCPDU5HUB9nolDkVRf2CBzzA6cXBsLMZEJud67O97Dp82fK0zJWWGr2EGLPAZH/IKj9ndBMezlYPMxRTXfbg4eAENCsBvWw+a0xiDsMBnfLg2VOdmcPsny+1uAmMhJaXleG5aXsW+/2RsNMMCnwmg8IjxISzDRCtz8g9gwnJft0knZ7HSAwt8JoCi49EzCcUwZqM0R7P/qLobZTRN6bDAZxiGMUC52lJbB8ICn2EYRobQKcC1FHfKK8EUgU9Eg4hoMxFtI6JshfNPEFE+Ea0jovlEdJEZ9TIMwzDaMSzwiSgewEcABgNoC+A2ImrrV2w1gCwhREcAkwG8abRehmEYLQghMCW3ECWloSdey8oFfly3P+D4udIynD3vDF96I5ih4XcHsE0IsUMIUQJgIoCh8gJCiF+EEF7Xj2UA0kyol2EYJiQ/rT+AJ79bi/fnbw1ZdvzSAszNLwo4PuCdX9Fp1BzFz4gQBpuFm4sDjn2XU6hQ0nrMEPiNAeyR7RdKx9S4D8BPSieIaAQR5RBRzsGDzliowDBMdHPsjMePXksIhKIgQc3OlZYrng9lw7/785UBZQ7EQvA0IroDQBaAt5TOCyHGCSGyhBBZqampkWwaI2P17iM4xbHeNTF20Xa7m8CYSKjJ1WHjloV13f8s3BbW58zGDIG/F0C6bD9NOuYDEfUHMBLAdUIIdvR2MK/M3IjHJq6xuxlRwes/bbK7CUwI9DjdhPLQ2XnoVFhtWOuQkCVmCPyVADKJqCkRJQIYBmCGvAARdQEwFh5hH2jQYhzHhn2R6aBCCGwp4tg0jPVMXLkH6/cew4qdh029bhS54RsX+EKIUgCPAJgNYCOASUKIDUT0EhFdJxV7C0BNAN8R0RoimqFyOSbG+C63EFe986vixBbDmMG24pMV29d8sBi3jP0dubuO2Ngi+0gw4yJCiFkAZvkde0G23d+Mehj3kS9lANpx8BT6tLK5MUzEyN93HG0aJYPIPzGg+fx3yc6AYwdPKFuVo0lbDwdeacvYitdmGoHn3jKOuSiaYiSYveEArn7/N3y/JmCqL2IcPKHsJROOvNe7MtdOWOAzjsCp8r74xFk8PnE1zpSU4eUf8xXzBRw+XWJDy6IXr4llS9HJECWt4x/TN9hWt52YYtJh3EekBLDTdKPycoFbxv6Oh65sjr6tG2D0T5vw/Zp9+H7NPgDAZ4sDzQOMewhHWXdaHw4Ga/iMrXgfsEjYcrVwsqQUObuO4N4vckImsGaiG7NMMfuPhbeIyo4sWCzwGVvxLksPV97/sqkYq3ab53Eh9+g4qsNUs/foGfR9eyH2HztjWlsYa3l3XmCohVBhEsxke3HkTVos8BlHEK5+f88XK3HDv5ea0oaycuFzLQFg6qrQE4sEYMycLdhx6BQ++83dJp/SsnIUq0x4RhvvKcTWiaL517Bggc+YxrnSMoyZu0VXVEEnPWC/bvEdYr89e7Pmz05Z5QmG9anLbfyjfshH91fn48RZ455JzjDi2YcdZkwW+IxpfLVsN96fvxVjF+3Q/JkKee8AG75/3tKJK/eolIxd5uQfAACcOmc8VLAT3vU7DtrnKWSHOycLfMY0vJr9mTDihhsV9/5JpyPJqZLAQHMPf70KGdkzbWiNtThpRGYGt4z1DYYWTT714cACnzGNcJR0s56v56blYeP+4+ZcTCdD3l8ccGxmXmASDcZ5aAmZbBVs0mFcgb+ngxACpWVq2YbMW2mrJaNRMEZ8mWu8EfD48jOME2GBz5jGu3M9Xg+Fh31dE5+bth4tRirmvKn0w3fRFN6lr8+3uwmWY8YL2om/uNtf1SzwGVM4XVKKEkmL9zdnfLMitH3dDAHilIe1WBaYq7Ss3BW5UN3MSVmyH5eb8FngM8rsO3ZWs2mivFyg7Quzw6rH7Q/YiC9z0fofP9vdDEfilJ9+1IzKuDqRXHhFBHy7cjcysmdGTClggc+osqbwqKZyJar2+dBUrLQN+wrOZsEmjvPvZc2eo5i5LnAy++z5MnyzYrdtHjKHT1WuqI5kE4QA/jVnCwBto2AzYIHPqBLJzu8AN3xHsX7vMRw7fd7H3GA3i7ce8jFXedHq6fKnj5bg4QmrAtY7vD17M56dmoc5+UWmtFMvdo40vHWP+iE/IvWxwGdUef779ZbX4X2p7D58GgVh5gutvJZTjATG2HP4NK75YDE6vTQH7f+pz1R2pqQMj09cbYm74R2fLa/YPne+HJ8t3okpuYXIemUe1uzRNhoEPC8OAMgtOIJ7v1iJIuklclphPUMksDNInjwRy4Ewg7DpgQU+o4pWv/Zbxy0LXUgF76P20S/b0efthWFfx00cMRBff+rqQny/Zl+FqcAq3pu/FS//mI9npqwDAGw+oH0NxHlJwK4oOIwFm4pRdNwj6Ozy1CqXKQqRFP3/nOEbk//uz1dYXicLfMYwa3Vod4w6pWXlOHLKvGQqE5bvtizQ2bEznlg6pRq041PnSvHs1HWVB1RGYk4w69k5SDxyugQlpdZ6dbHAZzRTUloOIQTmbDhQMQw2GovEJVYYU3jxhw3o8vJcnCkx/sAXHjmN56bl4QGTFpOFItjv+MXSAnyzwrlxiZzUBwe9+6ulXl2mCHwiGkREm4loGxFlK5zvTUSriKiUiG4yo04mshQdP4uWz/+Eps/Owogvc/HJb54Aaf4RJvUSSTc4p/Oj5MESTiwif0rLPN/rYRNHDHL0aOP+NvKAX1xnEpyz58tMHVU6pQ8WHT+HHdI81r6j1uRVMCzwiSgewEcABgNoC+A2ImrrV2w3gLsBTDBaH2MPu/447bM/N78ICzYVGY8H4vesHT5Vgozsmfjf7wW6L/XF0gJs0mFL9mmGg9Q8M1ti1V35/+p6BJTaV621J70wfT2GfrQEhUdOhy6suz3O6Ac9Ri+w5LpmaPjdAWwTQuwQQpQAmAhgqLyAEKJACLEOgLFgJxHg7Pky/Lz+gN3NcBQnzp7HLWN/9zmWK6UBLDcoKP0/PeoHz0TWt2GEJp6+Zh8GvftbWO34ysZomwH4fSmTcwt1m3kibQ9/f8E21XP+XWSv38tBb9azvL2el/r3q0Mnp9GLg977lmCGwG8MQP50FkrHdENEI4goh4hyDh6MfL5HAHht1kY88FUucgoOG7rOip2HXZMTdcdBdXfJ0T9tMnRtf816upQsPNJf3c4g92gGczaEViLU5N3fv1uLbPmkpwZ2HzZH+zUDf6VAzcyk1UvHW+rtOVvw6DerjTQNgPuFvBxHTdoKIcYJIbKEEFmpqamW13fo5Dnc8O8lFW5hAFB4xKN9HD0dfkafJdsO4Zaxv+PjRdsNt9FupuQWYuhHS1TPnzMYoVLtWQtlYhFC4MvfCwzVLcdqjVhPJE4lm/LmAyd01eftx1YJM6VFUg9/vcrQNcs0NjZf5i78w9p9QctqmcOQf99uF/5mCPy9ANJl+2nSMcczccVurNp9FOOXFlQcM+O59w5ZdyosJDpfVo43f95kSoq4SPDkd2sNfT6v8FjQ82oPWKgHb97GYvxj+obghaKUaBU6M/P2B7yoe725QDF3rBzvJPVLP5j/e+o1DTplAtcqzBD4KwFkElFTIkoEMAzADBOuaznevhknU++8m+dKy8OOa+7t9HEKb49pq/fi3wu3VyyM+Xblbvz50/AXLjmdaz8MTA4iR+0bDjU3cMrkkAMOcAGvmAA3W+Bv3H88YiEaxv3qm95yz+HQk7mnpfmJQyfVtfEb/r0Ej09UNt9sK1Yf/WgR4Mt2GDPfRhOGBb4QohTAIwBmA9gIYJIQYgMRvURE1wEAEV1MRIUAbgYwlogcoZp55bnvcN6z8/CEVeg3ZhHenad/xWLFdRXEiDeOiNcU8syUPCzZ9ofuOtxOqAU9RieLnYyRO/P/WsrKBQa/9xv+b3yOoTZpZXJuof4PabjhVbuP4vs1yuYb/zSFRnBxtwJgkg1fCDFLCNFSCNFcCPGqdOwFIcQMaXulECJNCFFDCHGBEKKdGfUapdI7IFDDBzwmmXfnVQ5H9xw+jXOlob0lKkYONs6QfLhgKxZudn6kRjVb/c5Dp4LaX81+MLWsGI0UZeWB8yLh3q/3xbhSckLYWnQCbf7xc4CnjFnEhTEZIn95Z2TPREb2TDwxaY1i2V8Uoo+atdbg7PkyfBfOCyuKcNSkbaTxetF4TS9nSsoUlzWvKzyKU+dK0evNX/D379Zhbn4Rlm47pHpdbwe2I2ell7fnbMHdn6+0rX6tBJNjwYJJma3h+0dwjCSbDhxHRvbMCsH13vxAF8eT50o1hV0I1uV2HjqF56bl4cz5Msy2yPWYCHhxxgZkZM/UHNZB6V07dZXyNOA9Xyj3aa9Z53xZeUXYB73Egjt2gt0NsIqz58uQEEdIiFd/p30g+Q6Xl3tyrl786jxFW+d1Hy7BXZddBABYuKnYxzNg9T8GoG6NRJ/ywWz4Xjnln+N1waYiXNGyPuKVPhSl+AtRIUTgSzBMuW22Ph4J/V5+/4u2HMSCjUUYNbQ9Fm72dUHeeSgwXMXeo2fQ5eW5KBg9JEQdKscBXCkLTmeVLhIfR/hCcoLo/qq2VI9qL+8tRSfQskGypmv0H/MrkhLiKkylc//WG5kaP+vF7RO2gIs1/Nb/+Bm3f7o8dEF4Fo30H7Mo6MTWhn0eVzD/LqE0NA5mw/fiP3S894scfLZ4B/IKj+n235+94YDhdQNmM2fDAbw6c6PPsQkKSR6CPWRBzwXR8B/6Oherdx8B4BnuawkVHAnb7SIpDMW4X7dj+H9XYPzvuxTLmRk1Uu1KemoYv7QAGdkzNZUNx6Sj9t1f9c6v2KNjPYHcRXjAO7+a1g434VqBD3gWP2ml4I/gHcurePtrI0raSTANP9jzMHPdflz74WJ89Iv6qkUl/vJlLm76uHIlrJZ5BjlbivT5eGthxJe5mOvnqz1yWmB8/XAfsmCfm5V3ANf/eykmrtiNri/PRdYr87RcMbyG6ODUOc/v8tos38Vq/vdixFzl37/2qZjFXvwhHx+EcJf04h/GNxjhDFCDvbzvj9BksxCCBT4TiP/DqNRJKr1/9PV+72hhw75jOHTynCa3UPmcw+YDJzAvvwitnveNtnf0dAkmLFdPIXdIIYuRGWiZGAxb4Gsokz01T/P1jp+x3m1xwaZiTaFvgy1mGzBmUVBbvtr3qTRq/Ndc82Pmbw9jxXKwBVd6lZdwKRdOiaJjLSzwNeJ9XrRoY+UVGr4+ge+91KGTJch6ZR7GKDyQpWXl6Dl6AWbl7UfursM+oVQHvvsrpqwK9DL4+3fr8Ny0vAqzlJMI125q9qTtzLzAXKtmM2VVoeHQt1uLT2K+n6dK7q7D6Pv2QtsyRskJx98/2Hy5EceH7CnrNCsUL0xf76gAelbBAl8jubs8NuFAgR9YVlRo+IHngi1E+UPS3PZKy+I/VDDtHD9bir1Hz2DktDzkFBwJOO//wF37wWIclGzYRsMgmMHXy3f5DNODPWPBbNlmPpvHbVz1fOz0ed0vPX8/hNdmbcKOQ6eQ78AXuhaCzbEYmc2YuHIP5m/Ulif36+W7WcNnAinxU0d2HDyJV2fm+ww9y4PY8LXE1zlw3NfuumHfMUzK2YN1hUcr4oCXC20jiLy9x3DOwgw6ehk5bT3maXwIT54rRYnKS8osbex8WTk6vjjHlGuFw9CPgq9EViJeZYHH8P8aT5G3rfiEa4L+AZ4FW5pxz22r4lq3TC9fLNmJK1rVR9OUGpZc/6nJniiGTVNq4vZLmgCo1LI/+W0nRg7xTw1QiVZ/4SHvBwqFciEURxDRNioN1txbxv6O7hn1MOmBywLOmSWT/EMBRJpQzgJKxKu86E+FkSkrI3smrmyVis/v6Y5txSfQf8yvuLlbGt66uZPua1lBuRAYG6EghOyW6QJe/CEfN3+81PJ65Ksji45rW3Dy+/bgIRWIgDFzNiufVNHwFyssCNtsgReOUbzrEEK9oFaouJuapeG/NVvl+40gehcKlZSZO2L7RVoH4F0P4KTVpgV/nMbrBkNwayXalKVwcL3AB/Q/UOEg7ytmLdoUQj2xhIAn6bHW6wQ9r7NdZvDfJTsN1T49RFjcaGLsIn2jjPFLlf33jZCRPROvyNZNPP+9dg8ntxAD8j42BL7S8P/1WRsDDxqpQ1aJXPsM5lZmJF6+EKJipXA04s03oMU0o5TtabUe26zLCFisLOtvz38fuNYhHL5a5qAMYBFC7/qXaCQmBL7S8H+sybZbeQ1yl0H/XLBy1hhIxByONjI3vwjbDwYu27cTLe6VI2NQ2wxGgp83gJFkPUwl3qQxbiYmBH65AP727RqUlws8PXmt5mXiepDLLbnWSj5lzBs0ng5jgu7jRdvR71+LTGuDGWjxCNla5KyXlN0k+Hnp7FBItMMwSsSEwAc8iUcmrtyDSTnWTEipafjyhSPzNjo/XHGk8H5DWt6BeXuP4ZUf89Fz9AJL2xQtJMRHJsDepJV7cIxHD67C9W6ZcrQE0QoXufYuF2L7jp5Bi/o1AQCbDzhzYYwd3gne4GaFR7S5JX662DPJqxhxM8ZYFyJtpFk8PWUdJq6MPVu+m3Glhq82UeofkthMlssCtck1/Ln5RVi4uRgz1u4LGqrZTr5cVhDxOr1p5fT6oT/4VXiJssfM2WyJKc8Ojp05j/V7j2HXH6fw12+U0/6ZRSzYtWMJV2r4/cco26mt9C+WR4aU26W/XLYLXy4z343OCDf9ZykmP9ijYn9bcfTYyH/ecCAswe11b311Zj46pdfBusJjuKlbmtnNixjXfLAY3TPqqa5TMItiiwLrMfbgSoGvFq9mf5AMSmaQPWUdRt/Y0fFL03N2HUHx8bOoX6sqgPAiHEYrn/y2s2Lb7lW2RrFa2DPuw5k2hihl4so9eOq7tQHRDJ1I99fm4xebc966xcTCMNGCKQKfiAYR0WYi2kZE2Qrnk4joW+n8ciLKMKNeJ+KkZemh+Hjhdha6DBNDGBb4RBQP4CMAgwG0BXAbEflHDLsPwBEhRAsA7wB4w2i9jHGW68gIxjBM9GOGht8dwDYhxA4hRAmAiQCG+pUZCmC8tD0ZQD+Kdd86hmGYCGOGwG8MYI9sv1A6plhGCFEK4BiAC/wvREQjiCiHiHIOHjxoQtMYhmEYL46atBVCjBNCZAkhslJTU+1uDsMwjKswQ+DvBZAu20+TjimWIaIEALUBBA8GHyaRSnrsBlo1SLa7CQzDRBAzBP5KAJlE1JSIEgEMAzDDr8wMAMOl7ZsALBAWZQw+edbeRM6bXxlka/16+PnxXvjhkcvtbgbDMBHCsMCXbPKPAJgNYCOASUKIDUT0EhFdJxX7DMAFRLQNwBMAAlw3zUJLnlcrSUqIx3vDOtvaBi0UjB4CIkKHtNpoUq+6LW0YfUMHW+plmFjFFBu+EGKWEKKlEKK5EOJV6dgLQogZ0vZZIcTNQogWQojuQgjLljgGE/g3dPWfSzaXd2715AFVi/GeUjPR0vq14s2960Up2XokuKRZwLy9JuY90dtQve/f1gWJDo1rxDBW4rpeT0HuaMwt1mre13fxxGYpV4nRVqtaFUvr18pr1/tq1v+y+HtRI9zE8i3qG5t7aJZSA20aRff8xTUdG2HUde0w9aEeSEqw7jEeeXUby67NRB73CXyb6r2+S+XoQa7f//x4r8g3Ridd0uvY3YSQvDy0naHPPzmgJSb83yUYe2c3tG9cG1/c0x0T7r/EpNZFnvR61TG8Rwa6NqkbkPLQTMpiIbN3DOG64Gl22fBfkgkkuUmndcNa+P7hnqgST3h0grmhbFvUr6kr0mVKzUQcOhmY+DzOBpvOy39qr6v8nZdl4LLmKahVLbwum9kgGT2ap1Ts162RiB4tUoJ8InogC9UcpwcCZPThOg3fLoEvr9ffAalzeh20u7C2zzGjLpEP9WmueDzeT3j/9vSVsu2+yHvxKkP1mkWSZEMf0rGRaplemb4CuUX9mqifXDWs+urVcMb8iVnIf+UL64T3nWhhUPuGll2biTyuE/ih5P2f/SYsjeKVr3JBq6oUydoW7nvJ+6KokZSgmCO3epV4n/10mQdOtcR4JFd1xjyCkAxfqTWTVMv89+6L0Sy1Bp4Z1DrgXJ9W+hbmdbuorr4GOpxEmd0+ra51XlY1k1xnBIhpXPdrqmn4a14YAAB49foOOFdajskmRbWMjyOUlwkfAV5FzQNEntw8TIlfJUE+ktD2mZpJCTh5zt71Cf5oMUNUiY/Dgif7KJ57rF8mFm7WHn7Df+QTzdzWvQn+0rtyhGeF0eXenk3RvH4NNKhl3eiBiTwuFPiBx+7ukYE61SuH9EM7X2iawPcKXbkAq1XV87UG854wKn9U3xey414hN//JKyxP/hJp3GRZrlYlHmfOa18h/tzVrVEtsXIkZ8Uaxheu9Q94y7gB15l0tNjwe2WaF6fnyataAQASFCR4sHq0KPh3XNoEdav7mmC8LxYhAoVeweghPvvNJLfHBrWqorPDPHGuatfA0Of1yDinL4T7bHiWrvIJcdY+to/2bWHp9fUw5cHLAvo1Ez7uE/hxhKcGtgpZbswtnXRd95Km9RSPP9inOQpGD/HxdFGTRc3r16zY1mLSaJpSE41qV/M5Vlvmyx9Ks3OyS11SQnzoQiYxtLO1C+4Mo3O05y/vvT/zq9fr83ySc5m0CO7uHhl4vH/LsK9jNt0u8jx3bjLJ2YnrBD4A3N499MRs+8a1Q5Yxir8W/86tnX3ODVTRcr2hDmokxuOLey6uOP7pXVk+7VYS59d2urDyvHPlvQmYc3P39Mww5Trh0qRedV238tr1HQJelt4JcHmIjNYNQ3uBXdvpQnRKr4MuTeqgeX3PaLBZag1HClctZqt+resbqqNqFVeKQx9ceYdazCUX1qkWulCYqPVNf4+HsXf6DuUb1fZMkHkfYCJUJBoHgP5tG1SYeBLj49CtSaDnyUvXtcOUB3tI7XCexO/d0mPmSog3JlTMujWzvbZC8Vi/zIB9/1vpmKaujPiHxQCU55G0OAVUiSNMf7gnpj3UE+0lt+FwVz87gXF3BZrG9LjjTn6gh5nNcSTuFPh+Y2Slvl8zKQE1ErWbFbzXSAniRliJJLCDXU/pU8K/TGCpe3o2xVMDW+GuHhfhtRs6YOZffaNdJsTHVXRy54l74JO7umFpdl91TyaNmHVvzVJq4rbu6aELmsQjfvZxIuMvrwqBr/MdKq/21ovTMedvvU2d3zKTiSMuC1lGaWRSR2M4kxu6No7IqN9uXCnwtdpEw3nO+rfRPmxUegAr+qTCSaHSoq5N6mBAW4/5JzEhDg9f2QJJCfGoWiW+YkHXX2Wao/dFlimbM3AKSQnxPqMru0chcXGE12/oiPR61o345Pi/6IjUf3etCA0KhuLnZN89EaGlg/MjdFeZQ/OiZobq00rj8+pE7cgCXOeWqcSANsq2cqOypnmq8vA32HUnP9gDN/x7adDrVnxe6sNTH+oZtLy/F0P9WlXx1X2XoFO68zUWNdNDf5XfzIsDrVVhQSDDo53uTS/Ash2H0bB2VTx3dWu8NmuTJuEfb91IbrIAABaaSURBVLG3TyRRCwFxgUMi1DoFVwv85KQE5I0aqKls/eQkFJ84p6nsj49ejvR61X08ZpQI5omjzaQTPpdnRnecmH4hRlJ2jwzMgsjjAeYV1ID+3/2xfpm4oUtjZKTUQI8S7f78rRqaPwKMjyOUlQs8NbAVWjdMxn3jc0yvwwrc0ZtC455XvAyttkz5UDqUZ0KqFMOlcZ1qaN+4dlBhH6zzaJFT3ljtRic2nUawyUh/Qt25Wx5QIgIRYUTv5hVeNvLIq1qIjyNk6JxsnfB/l+D+y5vp+owWvGbEvq3ro1+IUZqZpNU1xyT35ADnuKRagSsFvlblT15u2MXBvTUe7dsCn9yVhQdVgpYpofziEarnrpTsje8N64IRvZvhmo4XBhaKIvwjYn5wW5eAMmqaeqgFdNGs4LdsIF+PUYlX4FsZG8fLZc0uMBQlVc2F0Y7fpXGdapj6oDEPG28/zGzgvHkvM3GlwNdL3otX4a/91FcX5r80EC0bJGNA2wZI0GBvDdbpK13oAvnLFc2w4rl+6JBWG89d3cawbddu7rz0Ip8VyBdo8nCSMGFw82Cf5hVuoE5CvrCpZlV7rKrhxnLycrlKaGlvrKdIBq29vEWKj/syAGRJwfK0mv7sTo0aKVxpw9du0vGQEBcXZPKwPqonhvc1KV2yYj7W72TrhslIq1vdJwqiG1j09JXoOXqB7s+F1PBDGHV+eORydNBhQookg9s3xHvDOuN0SRn6OPCFpAU1OfqfP3fD18t36wr/PbTzhZi+Zp9JLfOEFNErwEcOiY3MXu6SLnoJ4b98ZatUfDr8YuWTQS8bWqvwr/Lnx3u7TtgDnslwL4oT1SqfC2ltCPEV6xX2kTBFeMNzEBGGdm6M27o3UVQ0zGiKHQrrGzd2QHq96sge3Lrivn75ex+8caN6svqC0UNMdQddkt0X0x/pKVu8GPqL+Pyei/WNPqMYQxKGiOoR0Vwi2ir9Vww6TkQ/E9FRIvrRSH1asdu+q7Ty0f9crCC/Xz1CKFTZaPwaP9UYJC0ajQv39MzArQrzYE1TagSYW6ykcZ1qunM+xIo5BzCu4WcDmC+EyAQwX9pX4i0Adxqsy3REkAnUm7ul4dXr1TUTTSiZdIR6nW5HTyq+UGXTTZ7YdMKLOFh/1HwNB9xHKPwzmTnJxdZBTbEEowJ/KIDx0vZ4AH9SKiSEmA/ghMG6NKPZhq+giTdPrYH3hnXGWzd3CjveTlC3TG8bo1KP04/cvKX0u6h9C6Hc7JpcUB05z/c30DJ3o/YMJMbH4fO79Zkpe2WmVEyChrq+FvoaDHKmBye9TJyA0UnbBkKI/dL2AQCGHG+JaASAEQDQpEn4Qa3ipd7YWKNvrrfz5jzfH8lVE0wL3Rv0mXC5vJ/9eG9N5dQex6yM4EvpAa1xjbThBMEgz3VgBbMf7436yUmoqzO/75f3XQIAyMieqVrGaQrMdZ0bY2XBEZ8Un4wGgU9E8wAoZTIeKd8RQggiMtRVhRDjAIwDgKysrLCvVSMpAR/f0bUilrZqfX77ZgmQYMKjc3od9MpMwfND3J1RqJUUnjdcG34sYjSmTihaaQiZHAmq6whaqAWlfnXHJU0w7OJ05O46EvrzIa7lJkIKfCGE6riZiIqIqJEQYj8RNQJQbGrrDDCofaOQZSrs6Ra1QclDoGqV+AqNKdbQqgWGCpQVihXP9dP9mUjo90Z83we1a4jH+meGLGf1S6OS8O/Fu75kaGfPwkKjI5rrOgUuUCQiVAljpboDBnoArHvxGLXhzwAwXNoeDmC6wetFlGkP9cSI3s1MT/hQmT3oopBlx93ZDZP+Ejr0a7QiX3iluC5B4QHTa2P2J5JeIWZSYdJRODewfQO0aVQr7GsrxdG3G73eMWrPSQ+VRWBMIEZt+KMBTCKi+wDsAnALABBRFoAHhBD3S/u/AWgNoCYRFQK4Twgx22DdhumUXgedLMj1Wr9WVc15OK9qp2Qtcw+hViYrxYCpkRT59YBO0OyCaedGbOSRyAkbTHZfoHPOQA2jIz81nGjGsapJhjR8IcQfQoh+QohMIUR/IcRh6XiOV9hL+72EEKlCiGpCiDQnCHsmcniVfKVO7MBnLaoJtgbETC5t5hG+fVqFXincMa0OJtxfacZUe7n+5YpmupPR/OfPXYOe1/sid8B731Lct7STcRwPXOEJOKdlCB/J7FNyImf7VqfSSyewLU7QQge3rxyNtmqYjILRQ9CzucecEqp5WswuVeLiMFDniDeU+c4Jv2s4GI11pAYLfMZynh7UGgWjh2iKzpgVwrPKKh7tG3pCNBoZZKLJ8D93dEPPFp75Ke/LqVuGxz9fT/4Ff1kmF8mpyfaGOHDAexWAQ006DOMUFj9zpaHP33Fp6Al2o1TVGCvJDO2OCFg/aiA+vD0wJLUZeDXnrk3qYtPLg7SnEkRlpM27LvP9zomAdhfWxpQHtTsxtDQhnLHV5i9velInwAKfCYr/CssuTeqgWhXz/Kj9B9zhyrpIxJA3Qq/MFE2htQFlk05mfW0+9CmShtyjeQpqJiVortMIVXX2B69TQ5cm3hDGvudDrZ/x0u7CWiHj5jTU6bFlhQHoX7d0suCq4cECnwnK5/dUukje1C0N/7u3O94d1tmnzKN91XMJhMIJK1ydTu7z/dH2Qm0umY3rVMNvT1+Jpwa2srRNVmjF8itmD26NyQ8E1/S/GXFpyGs2S7U+oUkoL6Rwvimr5mxcGQ+fMQ+5BtW6YTKSq1bxmVh7tG+LsGMOKeGEyUmnoTd0r5XhBCL1fvZO9Aejls6omFaRUjMJf5wqUT0fjonOKjMTa/iMZprIBMk1HdVXMo+6rp0pdcQq0TDmcdOLWX4v4bzQru7QCO/c2kk14J+TvirW8JmQ7Hz9aqzZc7TC5goA/7y2HQqPnMGdl16ExIQ4PDs1r+LcJc3C97TRar91I08NbIV9R8+gSxPzFwM6GT2uk/3bNMCpc6V49fr2oQtHCCLg+i5peG/eVsXzYcXbZ5MOYxdE5CPsAY/73PcP91Qur6O3yjUqM0Jc6Emt5zQ6pdfBgr/3wemSUrubosqL17XDqB82oNtFirmOgjK4fUP8tP6AegENglFrEplwsWLkEk5MH6tggc84BqMTuCtH9keNJHMjMdpBooOT17dskIyv7w89WarEh7d3xfmy8oDjds/bWy2Ow/GUYj98xtEsye5bsa1HS+rXptJ/O5zn/vUbOuA9yWsoNTkp7ITzTiIhPi4i8W8iTXwc6XbhjDRGXj7RMPfCAp8xhcZ1quHloZ7J2gY6fJ+bpdbEjteuDrve27o3wdDOjcP+PMNYiTdyrl7YLZNxPHdeloE7L8sI+/N2D+0Ze3GOpVsfPZqrC/VPwpxzYLdMJuKYGYclGG5y8fPn/dusCW3gJmx/zxvof9tfu7oiHedgKelSkiyERk0p1Hc9k0JEG4UFPqPKDV3ZVGKU2tWcsTgoGojGF7/cs6xzem0AwBUtA0NGT3mwh67rOjXjFcMYxqpQsE6ga5M6uOiC6vj7VfpDHUy4/xK88ifn+JtbhTc2k9MndENRkYuAPLH95TSopW+1tFVPBNvwGVUuDWKbZCp559ZOGPVDPo6ePl9xrFHtqqhfqyqSq1bBoqfCi+TZo0VKTKTvu/fyDJSWleOenhl2N8U0nh3cBs8ObmN3MwJgDZ9RpEo8OSZWSaTIuCC8sA5KE2y/P9sP01UWpjG+JCXE49F+mUhKsEfDl/9+diZMeePGDrJ2WAMLfMYxNFXIbxtJ/FcTM0w4hONh81i/TNx6sfWJ5tmkwziC/93bHa0bOSssQr0aiTgcJAqil6wMflHECq0bJmPTgROK54Jp5aFySKT4Zfpy5EpbIqpHRHOJaKv0P6DnE1FnIvqdiDYQ0ToiutVInYw76d0yFfWT9SWrMBv/h+z7h0KbZOb8rTfS6lZHS40JShjnocdnILlqaB1Z6XpaHRMSJK+f7MGttTdKB0ZNOtkA5gshMgHMl/b9OQ3gLiFEOwCDALxLRLEVDpCJCvw1tPR6oeP8ez0zPrnL2qBejDN4rF9LS657lZQG8afHeuGFa9oaWsAYDKMmnaEA+kjb4wEsBPCMvIAQYotsex8RFQNIBXDUYN0MYxk3dk3TVb529dia4I5V9CRr14M3HElmg2RkWhjx1aiG30AIsV/aPgAgaLZeIuoOIBHAdpXzI4goh4hyDh48aLBpDGMPamGjGXcTDaFBQgp8IppHROsV/obKywlPbFvVWyaiRgC+BHCPECIwRqrnGuOEEFlCiKzU1MDVagwTKYg8dtfkpOCDYCXTbOd0tlhGE/KfMJjQzn2+v7braTDX39wtzZaIqCFNOkII1bskoiIiaiSE2C8J9GKVcrUAzAQwUgixLOzWMoyFdEqrjWmr9wKAT95ehunfpn7I3MLeCV0154MbujbG1FWe/vXWzZ0AAF/e1z2i+Q+M2vBnABgOYLT0f7p/ASJKBDANwP+EEJMN1sdECKui9TmZ4T0ycHlmClqwxw3jh5Y8C70yU/DOrZ0qgqj587f+LSsEfuVnImvJMPpqGQ1gABFtBdBf2gcRZRHRp1KZWwD0BnA3Ea2R/jobrJdhTIeIAoT9gLZBp6Wiwm7LRAYiwvVd0hwdE8iQhi+E+ANAP4XjOQDul7a/AvCVkXoY60lMiENJqeLUSkwz+saOeHpQa1z6+ny7m8JYRIKGnLNmvNdTk/UFULMCDq3AAABm/bWXz76dMUWcRGJCHBrWVl8Q5j9B16ZRLYtbxJhNVw0hNcxIRF61SjyWP9cP0x7SFyrZTDi0AgMAaFIvvMBhTCV5L16FKg5OQM4oo2UV7DCT4tw0qFVVVwpQs2GBzzAaSEqIw7kQJq/kGIsu6kbUxrXdm9aLaDusgtURBkB0ZhtiGKMoZadyMyzwGYaJWcbd1c1nX0nvub6Le1J9ssBnGCYmad0wWVPSlUf6tvDZXzlS24pbJ8ICn2E0MKSDZzGNm7Q9JhAlG35aXd+oqU5wrwwXFvgMgMChbCyutA3GGzd1xJLsvviXtCSeiR6eHKAc0rinhnzBuc/3ty31ohWwwGcAaE/QEKtUiY9D4zrVEBfH31O0cWXr+gHHfnv6SjyrIclIqPg50Qa7ZTKMAVj8Rx9v3NgB6SrrToQsVkaDWu4S9gBr+Ayjm3iZlt+ifk0bW8KEwy1Z6ZrKJcS5Tzy6746YsGBNVTvVZcGx2BQWXUx7qEfQ30x+7sv7ukeiSRGFBT7DMK5GHtG0i4a4OQBwTcdGaJbqvtEbC3yG0UnbCzlAmlsRLo93zQKfAcChFfTwyfAsu5vAWIxbTXUs8BlFtMQIj1VqcZC0qKJRHfuiUzoNFvhMAO0b18JUG2N2M4yZpOjwpa9TPREAcGGQHAjRDPvhMwH8tW8mWjdkOzUTe/TOTMFHt3cNmdoyWmGBzwBwr83SKurVSMRdl11kdzMYjfz0WC+s2Hk4ZDkiwpCOyknI3QALfCaAzk3q2N0Ex7PqHwPsbgKjgzaNanH6SRi04RNRPSKaS0Rbpf8BTq5EdBERrSKiNUS0gYgeMFInYz31k91pv2SYWMfopG02gPlCiEwA86V9f/YDuEwI0RnAJQCyiehCg/UyFvDAFc0x/eGedjeDYRiLMGrSGQqgj7Q9HsBCAM/ICwghSmS7SWDPIMeSrSF6IMMw0YtR4dtACLFf2j4AQHFqm4jSiWgdgD0A3hBC7FMpN4KIcogo5+DBgwabxjAMw8gJqeET0TwADRVOjZTvCCEEESmuSxZC7AHQUTLlfE9Ek4UQRQrlxgEYBwBZWVnuXuPMMAwTYUIKfCGEagJHIioiokZCiP1E1AhAcYhr7SOi9QB6AZisu7UMwzBM2Bg16cwAMFzaHg5gun8BIkojomrSdl0AlwPYbLBehmEYRidGBf5oAAOIaCuA/tI+iCiLiD6VyrQBsJyI1gJYBOBtIUSewXoZhmEYnRjy0hFC/AGgn8LxHAD3S9tzAXQ0Ug/DMAxjHHaRZBiGiRE4tALDMIxOJtx/CYpPnLO7Gbphgc8wDKOTHi1S7G5CWLBJh2EYJkZggc8wDBMjsMBnGIaJEVjgMwzDxAgs8BmGYWIEFvgMwzAxAgt8hmGYGIEFPsMwTIxAQjgz7DwRHQSwy8AlUgAcMqk5ToLvK/pw673xfTmTi4QQqUonHCvwjUJEOUKILLvbYTZ8X9GHW++N7yv6YJMOwzBMjMACn2EYJkZws8AfZ3cDLILvK/pw673xfUUZrrXhMwzDML64WcNnGIZhZLDAZxiGiRFcJ/CJaBARbSaibUSUbXd7lCCi/xJRMRGtlx2rR0RziWir9L+udJyI6H3pftYRUVfZZ4ZL5bcS0XDZ8W5ElCd95n0iogjdVzoR/UJE+US0gYgec9G9VSWiFUS0Vrq3UdLxpkS0XGrPt0SUKB1Pkva3SeczZNd6Vjq+mYgGyo7b1neJKJ6IVhPRjy67rwKpv6whohzpWNT3x7ARQrjmD0A8gO0AmgFIBLAWQFu726XQzt4AugJYLzv2JoBsaTsbwBvS9tUAfgJAAC4FsFw6Xg/ADul/XWm7rnRuhVSWpM8OjtB9NQLQVdpOBrAFQFuX3BsBqCltVwGwXGrHJADDpOMfA3hQ2n4IwMfS9jAA30rbbaV+mQSgqdRf4+3uuwCeADABwI/SvlvuqwBAit+xqO+P4f65TcPvDmCbEGKHEKIEwEQAQ21uUwBCiF8BHPY7PBTAeGl7PIA/yY7/T3hYBqAOETUCMBDAXCHEYSHEEQBzAQySztUSQiwTnh75P9m1LEUIsV8IsUraPgFgI4DGLrk3IYQ4Ke1Wkf4EgL4AJqvcm/eeJwPoJ2l/QwFMFEKcE0LsBLANnn5rW98lojQAQwB8Ku0TXHBfQYj6/hgubhP4jQHske0XSseigQZCiP3S9gEADaRttXsKdrxQ4XhEkYb6XeDRhF1xb5LZYw2AYnge+u0AjgohShXaU3EP0vljAC6A/nuOBO8CeBpAubR/AdxxX4DnpTyHiHKJaIR0zBX9MRw4ibkDEUIIIopaf1kiqglgCoDHhRDH5WbNaL43IUQZgM5EVAfANACtbW6SYYjoGgDFQohcIupjd3ss4HIhxF4iqg9gLhFtkp+M5v4YDm7T8PcCSJftp0nHooEiaYgI6X+xdFztnoIdT1M4HhGIqAo8wv5rIcRU6bAr7s2LEOIogF8AXAbPsN+rOMnbU3EP0vnaAP6A/nu2mp4AriOiAnjMLX0BvIfovy8AgBBir/S/GJ6XdHe4rD/qwu5JBDP/4Bmx7IBn0sg7QdTO7naptDUDvpO2b8F3IulNaXsIfCeSVkjH6wHYCc8kUl1pu550zn8i6eoI3RPBY8d81++4G+4tFUAdabsagN8AXAPgO/hObj4kbT8M38nNSdJ2O/hObu6AZ2LT9r4LoA8qJ22j/r4A1ACQLNteCmCQG/pj2N+J3Q2w4Ee+Gh7vkO0ARtrdHpU2fgNgP4Dz8Nj97oPHDjofwFYA82QdigB8JN1PHoAs2XXuhWdybBuAe2THswCslz7zIaQV1RG4r8vhsZmuA7BG+rvaJffWEcBq6d7WA3hBOt5Meui3SUIySTpeVdrfJp1vJrvWSKn9myHz6rC778JX4Ef9fUn3sFb62+Ct2w39Mdw/Dq3AMAwTI7jNhs8wDMOowAKfYRgmRmCBzzAMEyOwwGcYhokRWOAzDMPECCzwGYZhYgQW+AzDMDHC/wMD7VtH5IiiQAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After augmentation\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Initial audio shape\")\n",
        "plt.figure()\n",
        "plt.plot(audioTrs_train[3])\n",
        "plt.show()\n",
        "\n",
        "print(\"After augmentation\")\n",
        "plt.figure()\n",
        "plt.plot(train_aug[3])\n",
        "plt.plot(train_aug[4], 'r')\n",
        "plt.plot(train_aug[5], 'purple')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okMLgjMEfQwf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def preprocess_spec(x, sr):\n",
        "  S_DB = []\n",
        "  for i in range(x.shape[0]):\n",
        "    S = librosa.feature.melspectrogram(x[i], sr=sr, n_fft=2048, hop_length=512)\n",
        "    S_DB.append(np.stack([librosa.power_to_db(S, ref=np.max),librosa.power_to_db(S, ref=np.max),librosa.power_to_db(S, ref=np.max)], axis=2))\n",
        "\n",
        "  S_DB = np.stack(S_DB, axis = 0)\n",
        "  return S_DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W1xAfN1IQou",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "SPEC = True\n",
        "fuse = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYp8g_sGbCSF",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "if not download_audio_images and SPEC:\n",
        "  sr = 16000\n",
        "\n",
        "  #training \n",
        "  S_DB = []\n",
        "  for i in range(train_aug.shape[0]):\n",
        "    S = librosa.feature.melspectrogram(train_aug[i], sr=sr, n_fft=2048, hop_length=512)\n",
        "    S_DB.append(np.stack([librosa.power_to_db(S, ref=np.max),librosa.power_to_db(S, ref=np.max),librosa.power_to_db(S, ref=np.max)], axis=2))\n",
        "\n",
        "  S_DB = np.stack(S_DB, axis = 0)\n",
        "    \n",
        "  librosa.display.specshow(S_DB[2,:,:,0], sr=sr, x_axis='time', y_axis='mel')\n",
        "  plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "  # validation\n",
        "  S_DB_val = []\n",
        "  for i in range(audioTrs_val.shape[0]):\n",
        "    S = librosa.feature.melspectrogram(audioTrs_val[i], sr=sr, n_fft=2048, hop_length=512)\n",
        "    S_DB_val.append(np.stack([librosa.power_to_db(S, ref=np.max),librosa.power_to_db(S, ref=np.max),librosa.power_to_db(S, ref=np.max)], axis=2))\n",
        "\n",
        "  S_DB_val = np.stack(S_DB_val, axis = 0)\n",
        "\n",
        "  plt.figure()\n",
        "  librosa.display.specshow(S_DB_val[2,:,:,0], sr=sr, x_axis='time', y_axis='mel')\n",
        "  plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "  S_DB_test = []\n",
        "  for i in range(audioTrs_test.shape[0]):\n",
        "    S = librosa.feature.melspectrogram(audioTrs_test[i], sr=sr, n_fft=2048, hop_length=512)\n",
        "    S_DB_test.append(np.stack([librosa.power_to_db(S, ref=np.max),librosa.power_to_db(S, ref=np.max),librosa.power_to_db(S, ref=np.max)], axis=2))\n",
        "\n",
        "  S_DB_test = np.stack(S_DB_test, axis = 0)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qmmTDGL-vC7j"
      },
      "source": [
        "# Transformers Audio\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "145LIlgQvC7j"
      },
      "source": [
        "https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/vit_small_ds.ipynb#scrollTo=J7w214BrTr_g\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vE1J6UMvC7k",
        "outputId": "e87feaaa-7dee-49dd-f883-f00fe2b76480",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |                               | 10 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |                               | 20 kB 36.2 MB/s eta 0:00:01\r\u001b[K     |                               | 30 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |                              | 40 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |                              | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |                              | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |                              | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |                             | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |                             | 92 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |                             | 102 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                            | 112 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                            | 122 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                            | 133 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                           | 143 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                           | 153 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                           | 163 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                           | 174 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                          | 184 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                          | 194 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                          | 204 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                         | 215 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                         | 225 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                         | 235 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                         | 245 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                        | 256 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                        | 266 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                        | 276 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                       | 286 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                       | 296 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                       | 307 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                      | 317 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                      | 327 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                      | 337 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                      | 348 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                     | 358 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                     | 368 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                     | 378 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                    | 389 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                    | 399 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                    | 409 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                    | 419 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                   | 430 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                   | 440 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                   | 450 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                  | 460 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                  | 471 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                  | 481 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                 | 491 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                 | 501 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                 | 512 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                 | 522 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                | 532 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                | 542 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |                | 552 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |               | 563 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |               | 573 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |               | 583 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |               | 593 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |              | 604 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |              | 614 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |              | 624 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |             | 634 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |             | 645 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |             | 655 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |            | 665 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |            | 675 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |            | 686 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |            | 696 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |           | 706 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |           | 716 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |           | 727 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |          | 737 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |          | 747 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |          | 757 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |          | 768 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |         | 778 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |         | 788 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |         | 798 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |        | 808 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |        | 819 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |        | 829 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |       | 839 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |       | 849 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |       | 860 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |       | 870 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |      | 880 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |      | 890 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |      | 901 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |     | 911 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |     | 921 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |     | 931 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |    | 942 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |    | 952 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |    | 962 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |    | 972 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |   | 983 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |   | 993 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |   | 1.0 MB 7.8 MB/s eta 0:00:01\r\u001b[K     |  | 1.0 MB 7.8 MB/s eta 0:00:01\r\u001b[K     |  | 1.0 MB 7.8 MB/s eta 0:00:01\r\u001b[K     |  | 1.0 MB 7.8 MB/s eta 0:00:01\r\u001b[K     |  | 1.0 MB 7.8 MB/s eta 0:00:01\r\u001b[K     | | 1.1 MB 7.8 MB/s eta 0:00:01\r\u001b[K     | | 1.1 MB 7.8 MB/s eta 0:00:01\r\u001b[K     | | 1.1 MB 7.8 MB/s eta 0:00:01\r\u001b[K     || 1.1 MB 7.8 MB/s eta 0:00:01\r\u001b[K     || 1.1 MB 7.8 MB/s eta 0:00:01\r\u001b[K     || 1.1 MB 7.8 MB/s eta 0:00:01\r\u001b[K     || 1.1 MB 7.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ViT\n",
        "!pip install -qq -U tensorflow-addons\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "import math\n",
        "\n",
        "# Setting seed for reproducibiltiy\n",
        "SEED = 42\n",
        "keras.utils.set_random_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4_BgU-cvC7m",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# DATA\n",
        "BATCH_SIZE = 16                                                                      \n",
        "\n",
        "# AUGMENTATION\n",
        "IMAGE_SIZE = 72                                                                 \n",
        "                             \n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 0.001                                                                \n",
        "WEIGHT_DECAY = 0.0001                                                                 \n",
        "\n",
        "# ARCHITECTURE\n",
        "LAYER_NORM_EPS = 1e-6     \n",
        "\n",
        "NUM_HEADS=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IajZz5fx3iIz",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Scale spectrogram values to match cv image sizes\n",
        "max_val = np.max([np.max(S_DB), np.max(S_DB_val), np.max(S_DB_test)])\n",
        "\n",
        "S_DB = 255/max_val*S_DB\n",
        "S_DB_val = 255/max_val*S_DB_val\n",
        "S_DB_test = 255/max_val*S_DB_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScTE7gqb5n91",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "fuse_id = []\n",
        "for i in range(S_DB.shape[0]):\n",
        "  fuse_id.append(i%3 == 0)\n",
        "S_DB_fuse = S_DB[fuse_id]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL_pbFxKKA3a",
        "outputId": "146623f3-d9cc-41fb-c298-1eb17d8aafbf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Person :\n",
            "(950,)\n",
            "(8550,)\n",
            "Frame :\n",
            "(950, 224, 224, 3)\n",
            "(2850, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "## Data adaptation for transformers\n",
        "\n",
        "# Downsampling\n",
        "import cv2\n",
        "def downsample_image(dataset, chosen_input_size):\n",
        "  # INTER_LINEAR or INTER_AREA\n",
        "  return [cv2.resize(image, (chosen_input_size, chosen_input_size), interpolation=cv2.INTER_AREA) for image in dataset]\n",
        "\n",
        "down_sample=True  # True to downsample dataset\n",
        "down_sampled=False\n",
        "fuse = True\n",
        "\n",
        "if down_sample and not down_sampled:\n",
        "  if not fuse:\n",
        "    chosen_input_size=S_DB[0].shape[1]\n",
        "\n",
        "    imgFrames_train=np.array(downsample_image(S_DB, chosen_input_size))\n",
        "    imgFrames_val=np.array(downsample_image(S_DB_val, chosen_input_size))\n",
        "    INPUT_SHAPE = (chosen_input_size, chosen_input_size, nb_channel)\n",
        "\n",
        "  else:\n",
        "    chosen_input_size=32\n",
        "    INPUT_SHAPE_IMG = (chosen_input_size, chosen_input_size, nb_channel)\n",
        "    imgFrames_train_img=np.array(downsample_image(imgFrames_train, chosen_input_size))\n",
        "    imgFrames_val_img=np.array(downsample_image(imgFrames_val, chosen_input_size))\n",
        "    imgFrames_test_img=np.array(downsample_image(imgFrames_test, chosen_input_size))\n",
        "\n",
        "    chosen_input_size=S_DB[0].shape[1]\n",
        "    INPUT_SHAPE_AUDIO = (chosen_input_size, chosen_input_size, nb_channel)\n",
        "\n",
        "    imgFrames_train_audio=np.array(downsample_image(S_DB_fuse, chosen_input_size))\n",
        "    imgFrames_val_audio=np.array(downsample_image(S_DB_val, chosen_input_size))\n",
        "    imgFrames_test_audio=np.array(downsample_image(S_DB_test, chosen_input_size))\n",
        "\n",
        "  down_sampled=True\n",
        "elif  not down_sample and not down_sampled:\n",
        "  if not fuse:\n",
        "    INPUT_SHAPE = (input_size, input_size, nb_channel)\n",
        "  else:\n",
        "    chosen_input_size=S_DB[0].shape[1]\n",
        "    INPUT_SHAPE_AUDIO = (chosen_input_size, chosen_input_size, nb_channel)\n",
        "    chosen_input_size=32\n",
        "    INPUT_SHAPE_IMG = (chosen_input_size, chosen_input_size, nb_channel)\n",
        "else :\n",
        "  print(\"Already downsampled\")\n",
        "\n",
        "print('Person :')\n",
        "print(np.shape(person_val_GT)) \n",
        "print(np.shape(train_aug_GT)) \n",
        "\n",
        "print('Frame :')\n",
        "print(np.shape(imgFrames_val)) \n",
        "print(np.shape(imgFrames_train)) \n",
        "\n",
        "NUM_CLASSES = nb_class\n",
        "\n",
        "\n",
        "# Normalization and shuffle\n",
        "norm=1 # already performed in data-augmentation\n",
        "\n",
        "if fuse:\n",
        "  x_train_img=imgFrames_train_img/norm\n",
        "  r=random.sample(range(len(x_train_img)), len(x_train_img)) # shuffle data\n",
        "  x_train_img=x_train_img[r]\n",
        "  y_train_fuse=person_train_GT[r]\n",
        "\n",
        "  x_train_audio=imgFrames_train_audio/norm\n",
        "  x_train_audio=x_train_audio[r]\n",
        "  #y_train_audio=train_aug_GT[r]\n",
        "\n",
        "  x_test_audio = imgFrames_test_audio/norm\n",
        "  x_test_img = imgFrames_test_img/norm\n",
        "  r=random.sample(range(len(x_test_audio)), len(x_test_audio)) # shuffle data\n",
        "  x_test_audio=x_test_audio[r]\n",
        "  x_test_img=x_test_img[r]\n",
        "\n",
        "  y_test_fuse=person_test_GT[r]\n",
        "\n",
        "\n",
        "  x_val_img=imgFrames_val_img/norm\n",
        "  r=random.sample(range(len(x_val_img)), len(x_val_img))\n",
        "  x_val_img=x_val_img[r]\n",
        "  y_val_fuse=person_val_GT[r]\n",
        "\n",
        "  x_val_audio=imgFrames_val_audio/norm\n",
        "  x_val_audio=x_val_audio[r]\n",
        "  #y_val_audio=person_val_GT[r]\n",
        "\n",
        "\n",
        "else:\n",
        "  x_train=imgFrames_train/norm\n",
        "  r=random.sample(range(len(x_train)), len(x_train)) # shuffle data\n",
        "  x_train=x_train[r]\n",
        "  y_train=train_aug_GT[r]\n",
        "\n",
        "  x_val=imgFrames_val/norm\n",
        "  r=random.sample(range(len(x_val)), len(x_val))\n",
        "  x_val=x_val[r]\n",
        "  y_val=person_val_GT[r]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbu_uFeJvC7m",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "if fuse:\n",
        "  data_augmentation.layers[0].adapt(x_train_img)\n",
        "else:\n",
        "  data_augmentation.layers[0].adapt(x_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmpW5nX4BavV",
        "outputId": "38375140-86fc-4bf6-8757-62e338e3915e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-30 13:18:28--  https://upload.wikimedia.org/wikipedia/commons/f/f9/Zoorashia_elephant.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 198.35.26.112, 2620:0:863:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|198.35.26.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168370 (164K) [image/jpeg]\n",
            "Saving to: elephant.jpg\n",
            "\n",
            "\relephant.jpg          0%[                    ]       0  --.-KB/s               \relephant.jpg        100%[===================>] 164.42K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-05-30 13:18:28 (2.75 MB/s) - elephant.jpg saved [168370/168370]\n",
            "\n",
            "total time: 50.46861964000004\n",
            "number of parameters per second: 507245892.2516308\n",
            "Equivalent number of parameter for augmentation image ViT: 3858.975464370349\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "import time  \n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/f/f9/Zoorashia_elephant.jpg -O elephant.jpg\n",
        "numTry = 1000\n",
        "numParam = 25.6e6\n",
        "\n",
        "with tf.device('/gpu:0'): # if using gpu for preprocessing /gpu:0\n",
        "  model = ResNet50(weights='imagenet')  # num of params: 25.6 M\n",
        "  img_path = 'elephant.jpg'\n",
        "  img = image.load_img(img_path, target_size=(224, 224))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "\n",
        "  tic = time.perf_counter()\n",
        "  for i in range(numTry):\n",
        "    preds = model.predict(x)\n",
        "\n",
        "  toc = time.perf_counter()\n",
        "  totTime=toc-tic\n",
        "  print(\"total time:\",totTime)\n",
        "  perRunTime = totTime/numTry\n",
        "  paramSpeed=numParam/perRunTime\n",
        "  print(\"number of parameters per second:\",paramSpeed)\n",
        "  tic = time.perf_counter()\n",
        "  test_data_augmented = data_augmentation(x_train_img)\n",
        "  toc = time.perf_counter()\n",
        "  totTime=toc-tic\n",
        "  perRunTime = totTime/(x_train_img.shape[0]) \n",
        "  print(\"Equivalent number of parameter for augmentation image ViT: {:}\".format(perRunTime*paramSpeed))\n",
        "  # time your preprocessing operation for one sample and multiply with this\n",
        "  # value to calculate parameter count equivalency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQvfuPKPsrHZ",
        "outputId": "bf1f5eb1-2204-44d7-f283-c22b04585d60",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |                             | 10 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |                           | 20 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |                        | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |                      | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |                   | 51 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |                 | 61 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |              | 71 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |            | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |          | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |       | 102 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |     | 112 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |  | 122 kB 6.5 MB/s eta 0:00:01\r\u001b[K     || 133 kB 6.5 MB/s eta 0:00:01\r\u001b[K     || 133 kB 6.5 MB/s \n",
            "\u001b[?25h"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-tuner\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch, Hyperband, BayesianOptimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7dkAb7bvC7m",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class ShiftedPatchTokenization(layers.Layer):\n",
        "    def __init__(\n",
        "        self, hp,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        vanilla=False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vanilla = vanilla  # Flag to swtich to vanilla patch extractor\n",
        "        self.image_size = image_size\n",
        "        self.patch_size = hp.Choice('patch_size',values=[4, 6, 12, 18, 24]) \n",
        "        self.half_patch = self.patch_size // 2\n",
        "        self.flatten_patches = layers.Reshape(((self.image_size // self.patch_size) ** 2 , -1))\n",
        "        self.projection = layers.Dense(units=hp.Choice('projection_dim',values=[32, 64, 128]))\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n",
        "\n",
        "    def crop_shift_pad(self, images, mode):\n",
        "        # Build the diagonally shifted images\n",
        "        if mode == \"left-up\":\n",
        "            crop_height = self.half_patch\n",
        "            crop_width = self.half_patch\n",
        "            shift_height = 0\n",
        "            shift_width = 0\n",
        "        elif mode == \"left-down\":\n",
        "            crop_height = 0\n",
        "            crop_width = self.half_patch\n",
        "            shift_height = self.half_patch\n",
        "            shift_width = 0\n",
        "        elif mode == \"right-up\":\n",
        "            crop_height = self.half_patch\n",
        "            crop_width = 0\n",
        "            shift_height = 0\n",
        "            shift_width = self.half_patch\n",
        "        else:\n",
        "            crop_height = 0\n",
        "            crop_width = 0\n",
        "            shift_height = self.half_patch\n",
        "            shift_width = self.half_patch\n",
        "\n",
        "        # Crop the shifted images and pad them\n",
        "        crop = tf.image.crop_to_bounding_box(\n",
        "            images,\n",
        "            offset_height=crop_height,\n",
        "            offset_width=crop_width,\n",
        "            target_height=self.image_size - self.half_patch,\n",
        "            target_width=self.image_size - self.half_patch,\n",
        "        )\n",
        "        shift_pad = tf.image.pad_to_bounding_box(\n",
        "            crop,\n",
        "            offset_height=shift_height,\n",
        "            offset_width=shift_width,\n",
        "            target_height=self.image_size,\n",
        "            target_width=self.image_size,\n",
        "        )\n",
        "        return shift_pad\n",
        "\n",
        "    def call(self, images):\n",
        "        if not self.vanilla:\n",
        "            # Concat the shifted images with the original image\n",
        "            images = tf.concat(\n",
        "                [\n",
        "                    images,\n",
        "                    self.crop_shift_pad(images, mode=\"left-up\"),\n",
        "                    self.crop_shift_pad(images, mode=\"left-down\"),\n",
        "                    self.crop_shift_pad(images, mode=\"right-up\"),\n",
        "                    self.crop_shift_pad(images, mode=\"right-down\"),\n",
        "                ],\n",
        "                axis=-1,\n",
        "            )\n",
        "        # Patchify the images and flatten it\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        flat_patches = self.flatten_patches(patches)\n",
        "        if not self.vanilla:\n",
        "            # Layer normalize the flat patches and linearly project it\n",
        "            tokens = self.layer_norm(flat_patches)\n",
        "            tokens = self.projection(tokens)\n",
        "        else:\n",
        "            # Linearly project the flat patches\n",
        "            tokens = self.projection(flat_patches)\n",
        "        return (tokens, patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOcSOSxSvC7o",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(\n",
        "        self, hp,  images_size=IMAGE_SIZE, **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patches = (images_size // hp.Choice('patch_size',values=[4, 6, 12, 18, 24])) ** 2\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=self.num_patches, output_dim=hp.Choice('projection_dim',values=[32, 64, 128]) \n",
        "        )\n",
        "        self.positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "\n",
        "    def call(self, encoded_patches):\n",
        "        encoded_positions = self.position_embedding(self.positions)\n",
        "        encoded_patches = encoded_patches + encoded_positions\n",
        "        return encoded_patches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbMuHN91vC7o",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLSA(tf.keras.layers.MultiHeadAttention):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # Tandhe trainable temperature term. The initial value is\n",
        "        # the square root of the key dimension.\n",
        "        self.tau = tf.Variable(math.sqrt(float(self._key_dim)), trainable=True)\n",
        "\n",
        "    def _compute_attention(self, query, key, value, attention_mask=None, training=None):\n",
        "        query = tf.multiply(query, 1.0 / self.tau)\n",
        "        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
        "        #print(attention_scores.shape,key.shape, query.shape)\n",
        "       # print(\"x1\", attention_scores.shape, attention_mask.shape)\n",
        "\n",
        "        attention_scores = self._masked_softmax(attention_scores, attention_mask)\n",
        "\n",
        "        attention_scores_dropout = self._dropout_layer(\n",
        "            attention_scores, training=training\n",
        "        )\n",
        "\n",
        "        attention_output = tf.einsum(\n",
        "            self._combine_equation, attention_scores_dropout, value\n",
        "        )\n",
        "\n",
        "        return attention_output, attention_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SurBdjv1Kx0n",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.activations import softmax\n",
        "class MultiHeadCrossAttention(tf.keras.layers.MultiHeadAttention):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # The trainable temperature term. The initial value is\n",
        "        # the square root of the key dimension.\n",
        "        self.tau = tf.Variable(math.sqrt(float(self._key_dim)), trainable=True)\n",
        "\n",
        "    def _compute_attention(self, query, key, value, attention_mask=None, training=None):\n",
        "\n",
        "        query = tf.multiply(query, 1.0 / self.tau)\n",
        "\n",
        "        key = tf.expand_dims(key, axis = 2)\n",
        "        query = tf.expand_dims(query, axis = 2)\n",
        "        value = tf.expand_dims(value, axis = 2)\n",
        "        key_t = tf.transpose(key , perm=[0,1,3,2])\n",
        "\n",
        "        attention_scores = tf.multiply(query,key_t)\n",
        "        attention_scores2 = tf.divide(attention_scores,  22.62741)\n",
        "        attention_scores3 = softmax(attention_scores2, axis=1)\n",
        "        attention_scores4 = tf.einsum('nmij,nmkj->nmki', attention_scores3, value)\n",
        "        attention_output = tf.concat([attention_scores4[:,0,:,:],attention_scores4[:,1,:,:],attention_scores4[:,2,:,:],attention_scores4[:,3,:,:]], axis=2)\n",
        "        return attention_output, attention_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvtRPkfXvC7p",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "def ffn(x,x_dim, emb):\n",
        "    x = layers.Dense(x_dim, activation=tf.nn.gelu)(x)\n",
        "    x = layers.Dense(emb)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0ieAV7EZBuA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "class create_vit_fused_classifier(kt.HyperModel):\n",
        "\n",
        "  def __init__(self,input_shape_img = INPUT_SHAPE_IMG, input_shape_audio = INPUT_SHAPE_AUDIO):\n",
        "    self.input_shape_img = input_shape_img\n",
        "    self.input_shape_audio=input_shape_audio\n",
        "    \n",
        "      \n",
        "  def build(self, hp, vanilla=False, image_size=IMAGE_SIZE):\n",
        "    # Face stream\n",
        "    inputs_img = layers.Input(shape=INPUT_SHAPE_IMG)\n",
        "\n",
        "    # Build the diagonal attention mask\n",
        "    diag_attn_mask = 1 - tf.eye((image_size // hp.Choice('patch_size',values=[4, 6, 12, 18, 24])) ** 2)\n",
        "    diag_attn_mask = tf.cast([diag_attn_mask], dtype=tf.int8)\n",
        "\n",
        "    # Augment data.\n",
        "    augmented_img = data_augmentation(inputs_img)\n",
        "    # Create patches.\n",
        "    (tokens_img, _) = ShiftedPatchTokenization(hp, vanilla=vanilla)(augmented_img)\n",
        "    # Encode patches.\n",
        "    encoded_img_patches = PatchEncoder(hp)(tokens_img)\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(hp.Choice('transformer_layers',values=[2, 4, 6, 8])):\n",
        "        # Layer normalization 1.\n",
        "        x1_img = layers.LayerNormalization(epsilon=1e-6)(encoded_img_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        if not vanilla:\n",
        "            attention_output_img = MultiHeadAttentionLSA(\n",
        "                num_heads=NUM_HEADS, key_dim=hp.Choice('projection_dim',values=[32, 64, 128]), dropout=0.1\n",
        "            )(x1_img, x1_img, attention_mask=diag_attn_mask)\n",
        "        else:\n",
        "            attention_output_img = layers.MultiHeadAttention(\n",
        "                num_heads=NUM_HEADS, key_dim=hp.Choice('projection_dim',values=[32, 64, 128]), dropout=0.1\n",
        "            )(x1_img, x1_img)\n",
        "        # Skip connection 1.\n",
        "        x2_img = layers.Add()([attention_output_img, encoded_img_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3_img = layers.LayerNormalization(epsilon=1e-6)(x2_img)\n",
        "        # MLP.\n",
        "        x3_img = mlp(x3_img, hidden_units=[hp.Choice('projection_dim',values=[32, 64, 128]) * 2, hp.Choice('projection_dim',values=[32, 64, 128]),] , dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_img_patches = layers.Add()([x3_img, x2_img])\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation_img = layers.LayerNormalization(epsilon=1e-6)(encoded_img_patches)\n",
        "    representation_img = layers.Flatten()(representation_img)\n",
        "    representation_img = layers.Dropout(0.5)(representation_img)\n",
        "    representation_img = mlp(representation_img, hidden_units=[2*hp.Choice('mlp_head_units',values=[512, 256, 128]), hp.Choice('mlp_head_units',values=[512, 256, 128])], dropout_rate=0.5)\n",
        "\n",
        "\n",
        "    img_stream_model = keras.Model(inputs=inputs_img, outputs=representation_img)\n",
        "\n",
        "\n",
        "    # =========================================================================#\n",
        "\n",
        "    # Audio stream\n",
        "    inputs_audio = layers.Input(shape=INPUT_SHAPE_AUDIO)\n",
        "    # Augment data.\n",
        "    augmented_audio = data_augmentation(inputs_audio)\n",
        "    # Create patches.\n",
        "    (tokens_audio, _) = ShiftedPatchTokenization(hp, vanilla=vanilla)(augmented_audio)\n",
        "    # Encode patches.\n",
        "    encoded_audio_patches = PatchEncoder(hp)(tokens_audio)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(hp.Choice('transformer_layers',values=[2, 4, 6, 8])):\n",
        "        # Layer normalization 1.\n",
        "        x1_audio = layers.LayerNormalization(epsilon=1e-6)(encoded_audio_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        if not vanilla:\n",
        "            attention_output_audio = MultiHeadAttentionLSA(\n",
        "                num_heads=NUM_HEADS, key_dim=hp.Choice('projection_dim',values=[32, 64, 128]), dropout=0.1\n",
        "            )(x1_audio, x1_audio, attention_mask=diag_attn_mask)\n",
        "        else:\n",
        "            attention_output_audio = layers.MultiHeadAttention(\n",
        "                num_heads=NUM_HEADS, key_dim=hp.Choice('projection_dim',values=[32, 64, 128]), dropout=0.1\n",
        "            )(x1_audio, x1_audio)\n",
        "        # Skip connection 1.\n",
        "        x2_audio = layers.Add()([attention_output_audio, encoded_audio_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3_audio = layers.LayerNormalization(epsilon=1e-6)(x2_audio)\n",
        "        # MLP.\n",
        "        x3_audio = mlp(x3_audio, hidden_units=[hp.Choice('projection_dim',values=[32, 64, 128]) * 2, hp.Choice('projection_dim',values=[32, 64, 128]),] , dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_audio_patches = layers.Add()([x3_audio, x2_audio])\n",
        "      # Create a [batch_size, projection_dim] tensor.\n",
        "    representation_audio = layers.LayerNormalization(epsilon=1e-6)(encoded_audio_patches)\n",
        "    representation_audio = layers.Flatten()(representation_audio)\n",
        "    representation_audio = layers.Dropout(0.5)(representation_audio)\n",
        "    representation_audio = mlp(representation_audio, hidden_units=[2*hp.Choice('mlp_head_units',values=[512, 256, 128]), hp.Choice('mlp_head_units',values=[512, 256, 128])], dropout_rate=0.5)\n",
        "    # End encoder stream \n",
        "\n",
        "    audio_stream_model = keras.Model(inputs=inputs_audio, outputs=representation_audio)\n",
        "\n",
        "    # ====================================================================\n",
        "    q2 = audio_stream_model.output\n",
        "    k1 = img_stream_model.output\n",
        "    v1 = img_stream_model.output\n",
        "    #print(\"qk\",q2.shape, k1.shape)\n",
        "\n",
        "    q1 = img_stream_model.output\n",
        "    k2 = audio_stream_model.output\n",
        "    v2 = audio_stream_model.output\n",
        "\n",
        "    # num_heads=hp.Choice('num_heads',values=[2,3,4,5,6,7,8])\n",
        "  # hp.Choice('mlp_head_units',values=[512, 256, 128])\n",
        "\n",
        "    attention_output_1 = MultiHeadCrossAttention(num_heads=NUM_HEADS, key_dim=hp.Choice('mlp_head_units',values=[512, 256, 128]), dropout=0.1)(query= q2, key= k1, value= v1)#, attention_mask=diag_attn_mask1)\n",
        "    attention_output_2 = MultiHeadCrossAttention(num_heads=NUM_HEADS, key_dim=hp.Choice('mlp_head_units',values=[512, 256, 128]), dropout=0.1)(query= q1, key= k2, value= v2)#, attention_mask=diag_attn_mask1)\n",
        "    #print(\"after MHCA\",attention_output_1.shape,attention_output_2.shape )\n",
        "    attention_output_1 = layers.Dense(hp.Choice('mlp_head_units',values=[512, 256, 128]), activation=None)(attention_output_1)\n",
        "    attention_output_2 = layers.Dense(hp.Choice('mlp_head_units',values=[512, 256, 128]), activation=None)(attention_output_2)\n",
        "\n",
        "    MHD_1 = layers.Add()([tf.expand_dims(img_stream_model.output, axis = 1), tf.expand_dims(attention_output_1, axis = 1)])\n",
        "    MHD_2 = layers.Add()([tf.expand_dims(audio_stream_model.output, axis = 1), tf.expand_dims(attention_output_2, axis = 1)])\n",
        "\n",
        "    output_MH = layers.Concatenate()([MHD_1, MHD_2])\n",
        "    # last linear output  \n",
        "    # Add MLP.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(output_MH)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    #print(representation.shape)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    #features = mlp(representation, hidden_units=MLP_HEAD_UNITS, dropout_rate=0.5)\n",
        "    features = ffn(representation, x_dim=hp.Choice('mlp_head_units',values=[512, 256, 128]), emb=hp.Choice('projection_dim',values=[32, 64, 128]))\n",
        "    \n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(NUM_CLASSES)(features)\n",
        "\n",
        "    model = keras.Model(inputs=[img_stream_model.input, audio_stream_model.input], outputs=logits)\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "  # def fit(self, hp, model, batch_size=BATCH_SIZE, *args, **kwargs):\n",
        "\n",
        "  #     return model.fit(*args,batch_size=batch_size,**kwargs,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHLjqe1g08vR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tuner_random_img = RandomSearch(create_vit_fused_classifier(input_shape_img = INPUT_SHAPE_IMG, input_shape_audio = INPUT_SHAPE_AUDIO), objective='val_accuracy', max_trials=5, executions_per_trial=1, project_name='Hyperparameters_random', overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu49i14-08yd",
        "outputId": "24bb9b7c-9ca9-4367-e291-8401476a7013",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "patch_size (Choice)\n",
            "{'default': 4, 'conditions': [], 'values': [4, 6, 12, 18, 24], 'ordered': True}\n",
            "projection_dim (Choice)\n",
            "{'default': 32, 'conditions': [], 'values': [32, 64, 128], 'ordered': True}\n",
            "transformer_layers (Choice)\n",
            "{'default': 2, 'conditions': [], 'values': [2, 4, 6, 8], 'ordered': True}\n",
            "mlp_head_units (Choice)\n",
            "{'default': 512, 'conditions': [], 'values': [512, 256, 128], 'ordered': True}\n"
          ]
        }
      ],
      "source": [
        "tuner_random_img.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SmRBaJQ081J",
        "outputId": "9c43bd94-732f-45b8-8a97-1a42e9060e77",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 03m 00s]\n",
            "val_accuracy: 0.3663157820701599\n",
            "\n",
            "Best val_accuracy So Far: 0.5673684477806091\n",
            "Total elapsed time: 00h 29m 01s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "tuner_random_img.search([x_train_img, x_train_audio], y_train_fuse, epochs=20,  validation_data=([x_val_img, x_val_audio], y_val_fuse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE_vGQZZNsdU",
        "outputId": "5295b554-cc73-4ee3-b3b8-43e4ccd9fa00",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./Hyperparameters_random\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f80a038e6d0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "patch_size: 6\n",
            "projection_dim: 64\n",
            "transformer_layers: 4\n",
            "mlp_head_units: 512\n",
            "Score: 0.5673684477806091\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "patch_size: 4\n",
            "projection_dim: 64\n",
            "transformer_layers: 4\n",
            "mlp_head_units: 128\n",
            "Score: 0.44631579518318176\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "patch_size: 4\n",
            "projection_dim: 32\n",
            "transformer_layers: 6\n",
            "mlp_head_units: 128\n",
            "Score: 0.4442105293273926\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "patch_size: 24\n",
            "projection_dim: 32\n",
            "transformer_layers: 8\n",
            "mlp_head_units: 512\n",
            "Score: 0.37684211134910583\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "patch_size: 18\n",
            "projection_dim: 32\n",
            "transformer_layers: 4\n",
            "mlp_head_units: 256\n",
            "Score: 0.3663157820701599\n"
          ]
        }
      ],
      "source": [
        "tuner_random_img.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtRRRPqidr1_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def custom_metric(model, y_pred, y_true):\n",
        "  acc = tf.metrics.accuracy(y_true, y_pred)[1]\n",
        "  param = model.counts_param()\n",
        "  ratio=param/10000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXpX7yU-u1o2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def plot_loss_and_accuracy(history_sl):\n",
        "  # model loss\n",
        "  loss='categorical_crossentropy'\n",
        "  metrics=['accuracy']\n",
        "\n",
        "  plt.plot(history_sl.history['loss'])\n",
        "  plt.plot(history_sl.history['val_loss'])\n",
        "  plt.title('Model loss : ' + loss)\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Validation'], loc='best')\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  # model accuracy metric\n",
        "  plt.plot(np.array(history_sl.history[metrics[0]]))\n",
        "  plt.plot(np.array(history_sl.history['val_' + metrics[0]]))\n",
        "  plt.title('Model accuracy metric : ' + metrics[0])\n",
        "  plt.ylabel('Accuracy metric')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Validation'], loc='best')\n",
        "  plt.show()\n",
        "  plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gRA7t9lNFlmx"
      },
      "source": [
        "# Test found parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29XSdYjbFr0n",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# DATA\n",
        "BUFFER_SIZE = 64 #512\n",
        "BATCH_SIZE = 32 #256\n",
        "\n",
        "# AUGMENTATION\n",
        "IMAGE_SIZE = 72 #72\n",
        "PATCH_SIZE = 6 #6\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "\n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "# TRAINING\n",
        "EPOCHS = 100\n",
        "\n",
        "# ARCHITECTURE\n",
        "LAYER_NORM_EPS = 1e-6#1e-6\n",
        "TRANSFORMER_LAYERS = 4 #8\n",
        "PROJECTION_DIM = 64\n",
        "NUM_HEADS = 4\n",
        "TRANSFORMER_UNITS = [\n",
        "    PROJECTION_DIM * 2,\n",
        "    PROJECTION_DIM,\n",
        "]\n",
        "\n",
        "MLP_LS = [1024,512]#[2048, 1024]\n",
        "\n",
        "MLP_HEAD_UNITS =[1024,512]# [2048, 1024]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD77AL2xXHzh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Build the diagonal attention mask\n",
        "diag_attn_mask = 1 - tf.eye(NUM_PATCHES)\n",
        "diag_attn_mask = tf.cast([diag_attn_mask], dtype=tf.int8)\n",
        "\n",
        "diag_attn_mask1 = 1 - tf.eye(MLP_LS[-1])\n",
        "diag_attn_mask1 = tf.cast([diag_attn_mask1], dtype=tf.int8)\n",
        "\n",
        "diag_attn_mask2 = 1 - tf.eye(NUM_PATCHES)\n",
        "diag_attn_mask2 = tf.cast([diag_attn_mask2], dtype=tf.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "895zbBmzWfTk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class ShiftedPatchTokenization_test(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        patch_size=PATCH_SIZE,\n",
        "        num_patches=NUM_PATCHES,\n",
        "        projection_dim=PROJECTION_DIM,\n",
        "        vanilla=False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vanilla = vanilla  # Flag to swtich to vanilla patch extractor\n",
        "        self.image_size = image_size\n",
        "        self.patch_size = patch_size\n",
        "        self.half_patch = patch_size // 2\n",
        "        self.flatten_patches = layers.Reshape((num_patches, -1))\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n",
        "\n",
        "    def crop_shift_pad(self, images, mode):\n",
        "        # Build the diagonally shifted images\n",
        "        if mode == \"left-up\":\n",
        "            crop_height = self.half_patch\n",
        "            crop_width = self.half_patch\n",
        "            shift_height = 0\n",
        "            shift_width = 0\n",
        "        elif mode == \"left-down\":\n",
        "            crop_height = 0\n",
        "            crop_width = self.half_patch\n",
        "            shift_height = self.half_patch\n",
        "            shift_width = 0\n",
        "        elif mode == \"right-up\":\n",
        "            crop_height = self.half_patch\n",
        "            crop_width = 0\n",
        "            shift_height = 0\n",
        "            shift_width = self.half_patch\n",
        "        else:\n",
        "            crop_height = 0\n",
        "            crop_width = 0\n",
        "            shift_height = self.half_patch\n",
        "            shift_width = self.half_patch\n",
        "\n",
        "        # Crop the shifted images and pad them\n",
        "        crop = tf.image.crop_to_bounding_box(\n",
        "            images,\n",
        "            offset_height=crop_height,\n",
        "            offset_width=crop_width,\n",
        "            target_height=self.image_size - self.half_patch,\n",
        "            target_width=self.image_size - self.half_patch,\n",
        "        )\n",
        "        shift_pad = tf.image.pad_to_bounding_box(\n",
        "            crop,\n",
        "            offset_height=shift_height,\n",
        "            offset_width=shift_width,\n",
        "            target_height=self.image_size,\n",
        "            target_width=self.image_size,\n",
        "        )\n",
        "        return shift_pad\n",
        "\n",
        "    def call(self, images):\n",
        "        if not self.vanilla:\n",
        "            # Concat the shifted images with the original image\n",
        "            images = tf.concat(\n",
        "                [\n",
        "                    images,\n",
        "                    self.crop_shift_pad(images, mode=\"left-up\"),\n",
        "                    self.crop_shift_pad(images, mode=\"left-down\"),\n",
        "                    self.crop_shift_pad(images, mode=\"right-up\"),\n",
        "                    self.crop_shift_pad(images, mode=\"right-down\"),\n",
        "                ],\n",
        "                axis=-1,\n",
        "            )\n",
        "        # Patchify the images and flatten it\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        flat_patches = self.flatten_patches(patches)\n",
        "        if not self.vanilla:\n",
        "            # Layer normalize the flat patches and linearly project it\n",
        "            tokens = self.layer_norm(flat_patches)\n",
        "            tokens = self.projection(tokens)\n",
        "        else:\n",
        "            # Linearly project the flat patches\n",
        "            tokens = self.projection(flat_patches)\n",
        "        return (tokens, patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlf9nqjrF_Cx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class PatchEncoder_test(layers.Layer):\n",
        "    def __init__(\n",
        "        self, num_patches=NUM_PATCHES, projection_dim=PROJECTION_DIM, **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patches = num_patches\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "        self.positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "\n",
        "    def call(self, encoded_patches):\n",
        "        encoded_positions = self.position_embedding(self.positions)\n",
        "        encoded_patches = encoded_patches + encoded_positions\n",
        "        return encoded_patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glqp4XsBGNlY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def create_vit_fused_classifier_test(vanilla=False):\n",
        "  # Face stream\n",
        "  inputs_img = layers.Input(shape=INPUT_SHAPE_IMG)\n",
        "  inputs_audio = layers.Input(shape=INPUT_SHAPE_AUDIO)\n",
        "\n",
        "  # Augment data.\n",
        "  augmented_img = data_augmentation(inputs_img)\n",
        "  # Create patches.\n",
        "  (tokens_img, _) = ShiftedPatchTokenization_test(vanilla=vanilla)(augmented_img)\n",
        "  # Encode patches.\n",
        "  encoded_img_patches = PatchEncoder_test()(tokens_img)\n",
        "\n",
        "  # Create multiple layers of the Transformer block.\n",
        "  for _ in range(TRANSFORMER_LAYERS):\n",
        "      # Layer normalization 1.\n",
        "      x1_img = layers.LayerNormalization(epsilon=1e-6)(encoded_img_patches)\n",
        "      # Create a multi-head attention layer.\n",
        "      if not vanilla:\n",
        "          attention_output_img = MultiHeadAttentionLSA(\n",
        "              num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n",
        "          )(x1_img, x1_img, attention_mask=diag_attn_mask)\n",
        "      else:\n",
        "          attention_output_img = layers.MultiHeadAttention(\n",
        "              num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n",
        "          )(x1_img, x1_img)\n",
        "      # Skip connection 1.\n",
        "      x2_img = layers.Add()([attention_output_img, encoded_img_patches])\n",
        "      # Layer normalization 2.\n",
        "      x3_img = layers.LayerNormalization(epsilon=1e-6)(x2_img)\n",
        "      # MLP.\n",
        "      x3_img = mlp(x3_img, hidden_units=TRANSFORMER_UNITS, dropout_rate=0.1)\n",
        "      # Skip connection 2.\n",
        "      encoded_img_patches = layers.Add()([x3_img, x2_img])\n",
        "      # Create a [batch_size, projection_dim] tensor.\n",
        "  representation_img = layers.LayerNormalization(epsilon=1e-6)(encoded_img_patches)\n",
        "  representation_img = layers.Flatten()(representation_img)\n",
        "  representation_img = layers.Dropout(0.5)(representation_img)\n",
        "  representation_img = mlp(representation_img, hidden_units=MLP_LS, dropout_rate=0.5)\n",
        "\n",
        "  img_stream_model = keras.Model(inputs=inputs_img, outputs=representation_img)\n",
        "\n",
        "  # =========================================================================#\n",
        "\n",
        "  # Audio stream\n",
        "  # Augment data.\n",
        "  augmented_audio = data_augmentation(inputs_audio)\n",
        "  # Create patches.\n",
        "  (tokens_audio, _) = ShiftedPatchTokenization_test(vanilla=vanilla)(augmented_audio)\n",
        "  # Encode patches.\n",
        "  encoded_audio_patches = PatchEncoder_test()(tokens_audio)\n",
        "\n",
        "  # Create multiple layers of the Transformer block.\n",
        "  for _ in range(TRANSFORMER_LAYERS):\n",
        "      # Layer normalization 1.\n",
        "      x1_audio = layers.LayerNormalization(epsilon=1e-6)(encoded_audio_patches)\n",
        "      # Create a multi-head attention layer.\n",
        "      if not vanilla:\n",
        "          attention_output_audio = MultiHeadAttentionLSA(\n",
        "              num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n",
        "          )(x1_audio, x1_audio, attention_mask=diag_attn_mask)\n",
        "      else:\n",
        "          attention_output_audio = layers.MultiHeadAttention(\n",
        "              num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n",
        "          )(x1_audio, x1_audio)\n",
        "      # Skip connection 1.\n",
        "      x2_audio = layers.Add()([attention_output_audio, encoded_audio_patches])\n",
        "      # Layer normalization 2.\n",
        "      x3_audio = layers.LayerNormalization(epsilon=1e-6)(x2_audio)\n",
        "      # MLP.\n",
        "      x3_audio = mlp(x3_audio, hidden_units=TRANSFORMER_UNITS, dropout_rate=0.1)\n",
        "      # Skip connection 2.\n",
        "      encoded_audio_patches = layers.Add()([x3_audio, x2_audio])\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "  representation_audio = layers.LayerNormalization(epsilon=1e-6)(encoded_audio_patches)\n",
        "  representation_audio = layers.Flatten()(representation_audio)\n",
        "  representation_audio = layers.Dropout(0.5)(representation_audio)\n",
        "  representation_audio = mlp(representation_audio, hidden_units=MLP_LS, dropout_rate=0.1)\n",
        "  # End encoder stream \n",
        "\n",
        "  audio_stream_model = keras.Model(inputs=inputs_audio, outputs=representation_audio)\n",
        "\n",
        "  # ====================================================================\n",
        "  q2 = audio_stream_model.output\n",
        "  k1 = img_stream_model.output\n",
        "  v1 = img_stream_model.output\n",
        "  #print(\"qk\",q2.shape, k1.shape)\n",
        "\n",
        "  q1 = img_stream_model.output\n",
        "  k2 = audio_stream_model.output\n",
        "  v2 = audio_stream_model.output\n",
        "\n",
        "  attention_output_1 = MultiHeadCrossAttention(num_heads=NUM_HEADS, key_dim=MLP_LS[-1], dropout=0.1)(query= q2, key= k1, value= v1)#, attention_mask=diag_attn_mask1)\n",
        "  attention_output_2 = MultiHeadCrossAttention(num_heads=NUM_HEADS, key_dim=MLP_LS[-1], dropout=0.1)(query= q1, key= k2, value= v2)#, attention_mask=diag_attn_mask1)\n",
        "\n",
        "  # linear layer \n",
        "  attention_output_1 = layers.Dense(MLP_LS[-1], activation=None)(attention_output_1)\n",
        "  attention_output_2 = layers.Dense(MLP_LS[-1], activation=None)(attention_output_2)\n",
        "\n",
        "  \n",
        "  MHD_1 = layers.Add()([tf.expand_dims(img_stream_model.output, axis = 1), tf.expand_dims(attention_output_1, axis = 1)])\n",
        "  MHD_2 = layers.Add()([tf.expand_dims(audio_stream_model.output, axis = 1), tf.expand_dims(attention_output_2, axis = 1)])\n",
        "\n",
        "  output_MH = layers.Concatenate()([MHD_1, MHD_2])\n",
        "\n",
        "  # last output  \n",
        "  representation = layers.LayerNormalization(epsilon=1e-6)(output_MH)\n",
        "  representation = layers.Flatten()(representation)\n",
        "  representation = layers.Dropout(0.5)(representation)\n",
        "  # Add FFN\n",
        "  features = ffn(representation, 512, 64)\n",
        "  \n",
        "  # Classify outputs.\n",
        "  logits = layers.Dense(NUM_CLASSES)(features)\n",
        "\n",
        "  model = keras.Model(inputs=[img_stream_model.input, audio_stream_model.input], outputs=logits)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjV4OVziGT46",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "def lr_step_decay(epoch, lr):\n",
        "    drop_rate = 0.1\n",
        "    epochs_drop =  100.0\n",
        "    return LEARNING_RATE * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
        "y_val_fuse_oh = tf.keras.utils.to_categorical(y_val_fuse, nb_class)  # create one-hot encoded class\n",
        "y_train_fuse_oh = tf.keras.utils.to_categorical(y_train_fuse, nb_class)  # create one-hot encoded class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jmDW-_XGTGt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Some code is taken from:\n",
        "# https://www.kaggle.com/ashusma/training-rfcx-tensorflow-tpu-effnet-b2.\n",
        "class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
        "    ):\n",
        "        super(WarmUpCosine, self).__init__()\n",
        "\n",
        "        self.learning_rate_base = learning_rate_base\n",
        "        self.total_steps = total_steps\n",
        "        self.warmup_learning_rate = warmup_learning_rate\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.pi = tf.constant(np.pi)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        if self.total_steps < self.warmup_steps:\n",
        "            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
        "\n",
        "        cos_annealed_lr = tf.cos(\n",
        "            self.pi\n",
        "            * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
        "            / float(self.total_steps - self.warmup_steps)\n",
        "        )\n",
        "        learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)\n",
        "\n",
        "        if self.warmup_steps > 0:\n",
        "            if self.learning_rate_base < self.warmup_learning_rate:\n",
        "                raise ValueError(\n",
        "                    \"Learning_rate_base must be larger or equal to \"\n",
        "                    \"warmup_learning_rate.\"\n",
        "                )\n",
        "            slope = (\n",
        "                self.learning_rate_base - self.warmup_learning_rate\n",
        "            ) / self.warmup_steps\n",
        "            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
        "            learning_rate = tf.where(\n",
        "                step < self.warmup_steps, warmup_rate, learning_rate\n",
        "            )\n",
        "        return tf.where(\n",
        "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
        "        )\n",
        "\n",
        "\n",
        "def run_fuse_experiment(model, train=True):\n",
        "    total_steps = int((len(x_train_img) / BATCH_SIZE) * EPOCHS)\n",
        "    warmup_epoch_percentage = 0.10\n",
        "    warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
        "    scheduled_lrs = WarmUpCosine(\n",
        "        learning_rate_base=LEARNING_RATE,\n",
        "        total_steps=total_steps,\n",
        "        warmup_learning_rate=0.0,\n",
        "        warmup_steps=warmup_steps,\n",
        "    )\n",
        "\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "    model.summary()\n",
        "    if train:\n",
        "      history = model.fit(\n",
        "          x=[x_train_img, x_train_audio],\n",
        "          y=y_train_fuse,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=150,\n",
        "          validation_data=([x_val_img, x_val_audio],y_val_fuse),\n",
        "          callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_step_decay, verbose=1)]\n",
        "      )\n",
        "    else:\n",
        "      history = []\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN2JxYaTHSqO",
        "outputId": "c39a4166-0094-466f-83de-09e839860b7b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 110, 110, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " data_augmentation (Sequential)  (None, 72, 72, 3)   7           ['input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " shifted_patch_tokenization_tes  ((None, 144, 64),   35704       ['data_augmentation[0][0]']      \n",
            " t (ShiftedPatchTokenization_te   (None, 12, 12, 540                                              \n",
            " st)                            ))                                                                \n",
            "                                                                                                  \n",
            " shifted_patch_tokenization_tes  ((None, 144, 64),   35704       ['data_augmentation[1][0]']      \n",
            " t_1 (ShiftedPatchTokenization_   (None, 12, 12, 540                                              \n",
            " test)                          ))                                                                \n",
            "                                                                                                  \n",
            " patch_encoder_test (PatchEncod  (None, 144, 64)     9216        ['shifted_patch_tokenization_test\n",
            " er_test)                                                        [0][0]']                         \n",
            "                                                                                                  \n",
            " patch_encoder_test_1 (PatchEnc  (None, 144, 64)     9216        ['shifted_patch_tokenization_test\n",
            " oder_test)                                                      _1[0][0]']                       \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 144, 64)     128         ['patch_encoder_test[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 144, 64)     128         ['patch_encoder_test_1[0][0]']   \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa (Mult  (None, 144, 64)     66369       ['layer_normalization_1[0][0]',  \n",
            " iHeadAttentionLSA)                                               'layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_4 (Mu  (None, 144, 64)     66369       ['layer_normalization_11[0][0]', \n",
            " ltiHeadAttentionLSA)                                             'layer_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 144, 64)      0           ['multi_head_attention_lsa[0][0]'\n",
            "                                                                 , 'patch_encoder_test[0][0]']    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 144, 64)      0           ['multi_head_attention_lsa_4[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'patch_encoder_test_1[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 144, 64)     128         ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_12 (LayerN  (None, 144, 64)     128         ['add_8[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 144, 128)     8320        ['layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 144, 128)     8320        ['layer_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 144, 128)     0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 144, 128)     0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 144, 64)      8256        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 144, 64)      8256        ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 144, 64)      0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 144, 64)      0           ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 144, 64)      0           ['dropout_1[0][0]',              \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 144, 64)      0           ['dropout_12[0][0]',             \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 144, 64)     128         ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_13 (LayerN  (None, 144, 64)     128         ['add_9[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_1 (Mu  (None, 144, 64)     66369       ['layer_normalization_3[0][0]',  \n",
            " ltiHeadAttentionLSA)                                             'layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_5 (Mu  (None, 144, 64)     66369       ['layer_normalization_13[0][0]', \n",
            " ltiHeadAttentionLSA)                                             'layer_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 144, 64)      0           ['multi_head_attention_lsa_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 144, 64)      0           ['multi_head_attention_lsa_5[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 144, 64)     128         ['add_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_14 (LayerN  (None, 144, 64)     128         ['add_10[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 144, 128)     8320        ['layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 144, 128)     8320        ['layer_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 144, 128)     0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 144, 128)     0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 144, 64)      8256        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 144, 64)      8256        ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 144, 64)      0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 144, 64)      0           ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 144, 64)      0           ['dropout_3[0][0]',              \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 144, 64)      0           ['dropout_14[0][0]',             \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 144, 64)     128         ['add_3[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 144, 64)     128         ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_2 (Mu  (None, 144, 64)     66369       ['layer_normalization_5[0][0]',  \n",
            " ltiHeadAttentionLSA)                                             'layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_6 (Mu  (None, 144, 64)     66369       ['layer_normalization_15[0][0]', \n",
            " ltiHeadAttentionLSA)                                             'layer_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 144, 64)      0           ['multi_head_attention_lsa_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 144, 64)      0           ['multi_head_attention_lsa_6[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 144, 64)     128         ['add_4[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_16 (LayerN  (None, 144, 64)     128         ['add_12[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 144, 128)     8320        ['layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 144, 128)     8320        ['layer_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 144, 128)     0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 144, 128)     0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 144, 64)      8256        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 144, 64)      8256        ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 144, 64)      0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 144, 64)      0           ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 144, 64)      0           ['dropout_5[0][0]',              \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 144, 64)      0           ['dropout_16[0][0]',             \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 144, 64)     128         ['add_5[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_17 (LayerN  (None, 144, 64)     128         ['add_13[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_3 (Mu  (None, 144, 64)     66369       ['layer_normalization_7[0][0]',  \n",
            " ltiHeadAttentionLSA)                                             'layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_7 (Mu  (None, 144, 64)     66369       ['layer_normalization_17[0][0]', \n",
            " ltiHeadAttentionLSA)                                             'layer_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 144, 64)      0           ['multi_head_attention_lsa_3[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 144, 64)      0           ['multi_head_attention_lsa_7[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_8 (LayerNo  (None, 144, 64)     128         ['add_6[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_18 (LayerN  (None, 144, 64)     128         ['add_14[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 144, 128)     8320        ['layer_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 144, 128)     8320        ['layer_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 144, 128)     0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 144, 128)     0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 144, 64)      8256        ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 144, 64)      8256        ['dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 144, 64)      0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 144, 64)      0           ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 144, 64)      0           ['dropout_7[0][0]',              \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 144, 64)      0           ['dropout_18[0][0]',             \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 144, 64)     128         ['add_7[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_19 (LayerN  (None, 144, 64)     128         ['add_15[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 9216)         0           ['layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 9216)         0           ['layer_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 9216)         0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 9216)         0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1024)         9438208     ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 1024)         9438208     ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 1024)         0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 1024)         0           ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 512)          524800      ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 512)          524800      ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 512)          0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 512)          0           ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " multi_head_cross_attention (Mu  (None, 512)         4200961     ['dropout_21[0][0]',             \n",
            " ltiHeadCrossAttention)                                           'dropout_10[0][0]',             \n",
            "                                                                  'dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " multi_head_cross_attention_1 (  (None, 512)         4200961     ['dropout_10[0][0]',             \n",
            " MultiHeadCrossAttention)                                         'dropout_21[0][0]',             \n",
            "                                                                  'dropout_21[0][0]']             \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 512)          262656      ['multi_head_cross_attention[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 512)          262656      ['multi_head_cross_attention_1[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (None, 1, 512)       0           ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (None, 1, 512)       0           ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " tf.expand_dims_2 (TFOpLambda)  (None, 1, 512)       0           ['dropout_21[0][0]']             \n",
            "                                                                                                  \n",
            " tf.expand_dims_3 (TFOpLambda)  (None, 1, 512)       0           ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 1, 512)       0           ['tf.expand_dims[0][0]',         \n",
            "                                                                  'tf.expand_dims_1[0][0]']       \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 1, 512)       0           ['tf.expand_dims_2[0][0]',       \n",
            "                                                                  'tf.expand_dims_3[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 1, 1024)      0           ['add_16[0][0]',                 \n",
            "                                                                  'add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_20 (LayerN  (None, 1, 1024)     2048        ['concatenate[0][0]']            \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1024)         0           ['layer_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 1024)         0           ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 512)          524800      ['dropout_22[0][0]']             \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 64)           32832       ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 49)           3185        ['dense_25[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 30,171,826\n",
            "Trainable params: 30,171,819\n",
            "Non-trainable params: 7\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/150\n",
            "90/90 [==============================] - 40s 216ms/step - loss: 4.0555 - accuracy: 0.0309 - top-5-accuracy: 0.1639 - val_loss: 3.8050 - val_accuracy: 0.0674 - val_top-5-accuracy: 0.2147 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 2/150\n",
            "90/90 [==============================] - 17s 193ms/step - loss: 3.6445 - accuracy: 0.0779 - top-5-accuracy: 0.2832 - val_loss: 3.4788 - val_accuracy: 0.0968 - val_top-5-accuracy: 0.3189 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 3/150\n",
            "90/90 [==============================] - 17s 193ms/step - loss: 3.4514 - accuracy: 0.1032 - top-5-accuracy: 0.3288 - val_loss: 3.3083 - val_accuracy: 0.1274 - val_top-5-accuracy: 0.3516 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 4/150\n",
            "90/90 [==============================] - 18s 198ms/step - loss: 3.2384 - accuracy: 0.1446 - top-5-accuracy: 0.3947 - val_loss: 3.1506 - val_accuracy: 0.1611 - val_top-5-accuracy: 0.4000 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 5/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 3.0553 - accuracy: 0.1832 - top-5-accuracy: 0.4519 - val_loss: 2.8993 - val_accuracy: 0.2021 - val_top-5-accuracy: 0.4832 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 6/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 2.8616 - accuracy: 0.2123 - top-5-accuracy: 0.5144 - val_loss: 2.7595 - val_accuracy: 0.2589 - val_top-5-accuracy: 0.5516 - lr: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 7/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 2.6853 - accuracy: 0.2379 - top-5-accuracy: 0.5807 - val_loss: 2.7127 - val_accuracy: 0.2642 - val_top-5-accuracy: 0.6032 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 8/150\n",
            "90/90 [==============================] - 18s 196ms/step - loss: 2.6044 - accuracy: 0.2625 - top-5-accuracy: 0.6011 - val_loss: 2.4778 - val_accuracy: 0.3147 - val_top-5-accuracy: 0.6284 - lr: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 9/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 2.4138 - accuracy: 0.3095 - top-5-accuracy: 0.6586 - val_loss: 2.2712 - val_accuracy: 0.3295 - val_top-5-accuracy: 0.7074 - lr: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 10/150\n",
            "90/90 [==============================] - 18s 198ms/step - loss: 2.3577 - accuracy: 0.3263 - top-5-accuracy: 0.6768 - val_loss: 2.1926 - val_accuracy: 0.3600 - val_top-5-accuracy: 0.7053 - lr: 0.0010\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 11/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 2.2767 - accuracy: 0.3368 - top-5-accuracy: 0.7018 - val_loss: 2.2287 - val_accuracy: 0.3684 - val_top-5-accuracy: 0.6958 - lr: 0.0010\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 12/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 2.2125 - accuracy: 0.3575 - top-5-accuracy: 0.7102 - val_loss: 2.1547 - val_accuracy: 0.3895 - val_top-5-accuracy: 0.7358 - lr: 0.0010\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 13/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 2.1303 - accuracy: 0.3789 - top-5-accuracy: 0.7302 - val_loss: 2.0488 - val_accuracy: 0.4021 - val_top-5-accuracy: 0.7284 - lr: 0.0010\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 14/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 2.0499 - accuracy: 0.3986 - top-5-accuracy: 0.7432 - val_loss: 1.9350 - val_accuracy: 0.4337 - val_top-5-accuracy: 0.7716 - lr: 0.0010\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 15/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 1.9713 - accuracy: 0.4235 - top-5-accuracy: 0.7600 - val_loss: 1.8537 - val_accuracy: 0.4705 - val_top-5-accuracy: 0.7916 - lr: 0.0010\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 16/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 1.8361 - accuracy: 0.4488 - top-5-accuracy: 0.7891 - val_loss: 1.8400 - val_accuracy: 0.4653 - val_top-5-accuracy: 0.7811 - lr: 0.0010\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 17/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 1.8291 - accuracy: 0.4579 - top-5-accuracy: 0.7996 - val_loss: 1.8323 - val_accuracy: 0.4442 - val_top-5-accuracy: 0.7989 - lr: 0.0010\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 18/150\n",
            "90/90 [==============================] - 17s 193ms/step - loss: 1.7260 - accuracy: 0.4758 - top-5-accuracy: 0.8172 - val_loss: 1.7199 - val_accuracy: 0.5116 - val_top-5-accuracy: 0.8295 - lr: 0.0010\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 19/150\n",
            "90/90 [==============================] - 17s 193ms/step - loss: 1.6952 - accuracy: 0.4821 - top-5-accuracy: 0.8246 - val_loss: 1.7195 - val_accuracy: 0.4926 - val_top-5-accuracy: 0.8053 - lr: 0.0010\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 20/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 1.6457 - accuracy: 0.5014 - top-5-accuracy: 0.8323 - val_loss: 1.6628 - val_accuracy: 0.5105 - val_top-5-accuracy: 0.8232 - lr: 0.0010\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 21/150\n",
            "90/90 [==============================] - 18s 195ms/step - loss: 1.5774 - accuracy: 0.5239 - top-5-accuracy: 0.8351 - val_loss: 1.5553 - val_accuracy: 0.5453 - val_top-5-accuracy: 0.8326 - lr: 0.0010\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 22/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 1.4813 - accuracy: 0.5449 - top-5-accuracy: 0.8611 - val_loss: 1.6077 - val_accuracy: 0.5211 - val_top-5-accuracy: 0.8400 - lr: 0.0010\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 23/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 1.4605 - accuracy: 0.5625 - top-5-accuracy: 0.8604 - val_loss: 1.5293 - val_accuracy: 0.5600 - val_top-5-accuracy: 0.8400 - lr: 0.0010\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 24/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 1.3774 - accuracy: 0.5698 - top-5-accuracy: 0.8796 - val_loss: 1.4429 - val_accuracy: 0.5800 - val_top-5-accuracy: 0.8463 - lr: 0.0010\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 25/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 1.4124 - accuracy: 0.5709 - top-5-accuracy: 0.8821 - val_loss: 1.3658 - val_accuracy: 0.5989 - val_top-5-accuracy: 0.8716 - lr: 0.0010\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 26/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 1.3455 - accuracy: 0.5965 - top-5-accuracy: 0.8765 - val_loss: 1.4150 - val_accuracy: 0.5905 - val_top-5-accuracy: 0.8642 - lr: 0.0010\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 27/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 1.2285 - accuracy: 0.6288 - top-5-accuracy: 0.9112 - val_loss: 1.4078 - val_accuracy: 0.6053 - val_top-5-accuracy: 0.8705 - lr: 0.0010\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 28/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 1.2633 - accuracy: 0.6095 - top-5-accuracy: 0.9119 - val_loss: 1.4340 - val_accuracy: 0.5874 - val_top-5-accuracy: 0.8705 - lr: 0.0010\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 29/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 1.1937 - accuracy: 0.6361 - top-5-accuracy: 0.9067 - val_loss: 1.2468 - val_accuracy: 0.6389 - val_top-5-accuracy: 0.8926 - lr: 0.0010\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 30/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 1.1639 - accuracy: 0.6432 - top-5-accuracy: 0.9179 - val_loss: 1.3191 - val_accuracy: 0.6189 - val_top-5-accuracy: 0.8905 - lr: 0.0010\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 31/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 1.1507 - accuracy: 0.6530 - top-5-accuracy: 0.9211 - val_loss: 1.2633 - val_accuracy: 0.6432 - val_top-5-accuracy: 0.8884 - lr: 0.0010\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 32/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 1.2478 - accuracy: 0.6260 - top-5-accuracy: 0.9032 - val_loss: 1.2973 - val_accuracy: 0.6368 - val_top-5-accuracy: 0.8926 - lr: 0.0010\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 33/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 1.1031 - accuracy: 0.6586 - top-5-accuracy: 0.9277 - val_loss: 1.1986 - val_accuracy: 0.6716 - val_top-5-accuracy: 0.9063 - lr: 0.0010\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 34/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 1.0997 - accuracy: 0.6646 - top-5-accuracy: 0.9270 - val_loss: 1.1877 - val_accuracy: 0.6821 - val_top-5-accuracy: 0.8958 - lr: 0.0010\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 35/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 1.0382 - accuracy: 0.6863 - top-5-accuracy: 0.9312 - val_loss: 1.1929 - val_accuracy: 0.6726 - val_top-5-accuracy: 0.9000 - lr: 0.0010\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 36/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 1.0242 - accuracy: 0.6905 - top-5-accuracy: 0.9337 - val_loss: 1.1060 - val_accuracy: 0.7116 - val_top-5-accuracy: 0.9042 - lr: 0.0010\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 37/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.9460 - accuracy: 0.7060 - top-5-accuracy: 0.9470 - val_loss: 1.1660 - val_accuracy: 0.6789 - val_top-5-accuracy: 0.9000 - lr: 0.0010\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 38/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.9733 - accuracy: 0.7063 - top-5-accuracy: 0.9404 - val_loss: 1.1751 - val_accuracy: 0.6874 - val_top-5-accuracy: 0.8968 - lr: 0.0010\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 39/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.9411 - accuracy: 0.7081 - top-5-accuracy: 0.9498 - val_loss: 1.0951 - val_accuracy: 0.7168 - val_top-5-accuracy: 0.9116 - lr: 0.0010\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 40/150\n",
            "90/90 [==============================] - 17s 187ms/step - loss: 1.0046 - accuracy: 0.7007 - top-5-accuracy: 0.9400 - val_loss: 1.0076 - val_accuracy: 0.7189 - val_top-5-accuracy: 0.9179 - lr: 0.0010\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 41/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.8529 - accuracy: 0.7407 - top-5-accuracy: 0.9502 - val_loss: 1.0884 - val_accuracy: 0.7126 - val_top-5-accuracy: 0.9084 - lr: 0.0010\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 42/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.8672 - accuracy: 0.7393 - top-5-accuracy: 0.9568 - val_loss: 1.0132 - val_accuracy: 0.7179 - val_top-5-accuracy: 0.9211 - lr: 0.0010\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 43/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.9165 - accuracy: 0.7221 - top-5-accuracy: 0.9425 - val_loss: 1.0608 - val_accuracy: 0.7032 - val_top-5-accuracy: 0.9232 - lr: 0.0010\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 44/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.8729 - accuracy: 0.7281 - top-5-accuracy: 0.9512 - val_loss: 1.0152 - val_accuracy: 0.7326 - val_top-5-accuracy: 0.9221 - lr: 0.0010\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 45/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.7900 - accuracy: 0.7575 - top-5-accuracy: 0.9593 - val_loss: 0.9904 - val_accuracy: 0.7400 - val_top-5-accuracy: 0.9232 - lr: 0.0010\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 46/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.8000 - accuracy: 0.7604 - top-5-accuracy: 0.9607 - val_loss: 1.0344 - val_accuracy: 0.7316 - val_top-5-accuracy: 0.9137 - lr: 0.0010\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 47/150\n",
            "90/90 [==============================] - 17s 187ms/step - loss: 0.7351 - accuracy: 0.7828 - top-5-accuracy: 0.9681 - val_loss: 0.9719 - val_accuracy: 0.7368 - val_top-5-accuracy: 0.9274 - lr: 0.0010\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 48/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.7452 - accuracy: 0.7828 - top-5-accuracy: 0.9625 - val_loss: 1.0152 - val_accuracy: 0.7347 - val_top-5-accuracy: 0.9158 - lr: 0.0010\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 49/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.8021 - accuracy: 0.7593 - top-5-accuracy: 0.9600 - val_loss: 0.9968 - val_accuracy: 0.7432 - val_top-5-accuracy: 0.9200 - lr: 0.0010\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 50/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.7089 - accuracy: 0.7891 - top-5-accuracy: 0.9677 - val_loss: 0.9835 - val_accuracy: 0.7695 - val_top-5-accuracy: 0.9158 - lr: 0.0010\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 51/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.6947 - accuracy: 0.7867 - top-5-accuracy: 0.9698 - val_loss: 0.9658 - val_accuracy: 0.7579 - val_top-5-accuracy: 0.9200 - lr: 0.0010\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 52/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.6857 - accuracy: 0.8011 - top-5-accuracy: 0.9656 - val_loss: 1.0181 - val_accuracy: 0.7516 - val_top-5-accuracy: 0.9084 - lr: 0.0010\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 53/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.6944 - accuracy: 0.7965 - top-5-accuracy: 0.9667 - val_loss: 0.8822 - val_accuracy: 0.7589 - val_top-5-accuracy: 0.9411 - lr: 0.0010\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 54/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.6470 - accuracy: 0.8042 - top-5-accuracy: 0.9775 - val_loss: 0.8512 - val_accuracy: 0.7874 - val_top-5-accuracy: 0.9326 - lr: 0.0010\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 55/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.7122 - accuracy: 0.7923 - top-5-accuracy: 0.9677 - val_loss: 0.9370 - val_accuracy: 0.7695 - val_top-5-accuracy: 0.9211 - lr: 0.0010\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 56/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.6593 - accuracy: 0.8095 - top-5-accuracy: 0.9723 - val_loss: 0.9672 - val_accuracy: 0.7505 - val_top-5-accuracy: 0.9305 - lr: 0.0010\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 57/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.6267 - accuracy: 0.8130 - top-5-accuracy: 0.9751 - val_loss: 0.9210 - val_accuracy: 0.7653 - val_top-5-accuracy: 0.9305 - lr: 0.0010\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 58/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.6212 - accuracy: 0.8193 - top-5-accuracy: 0.9733 - val_loss: 0.8289 - val_accuracy: 0.7937 - val_top-5-accuracy: 0.9379 - lr: 0.0010\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 59/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.5591 - accuracy: 0.8281 - top-5-accuracy: 0.9782 - val_loss: 0.8664 - val_accuracy: 0.7926 - val_top-5-accuracy: 0.9379 - lr: 0.0010\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 60/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.6071 - accuracy: 0.8151 - top-5-accuracy: 0.9733 - val_loss: 0.8754 - val_accuracy: 0.7842 - val_top-5-accuracy: 0.9347 - lr: 0.0010\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 61/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.6118 - accuracy: 0.8228 - top-5-accuracy: 0.9779 - val_loss: 0.8742 - val_accuracy: 0.7905 - val_top-5-accuracy: 0.9295 - lr: 0.0010\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 62/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.5171 - accuracy: 0.8386 - top-5-accuracy: 0.9818 - val_loss: 0.8509 - val_accuracy: 0.7905 - val_top-5-accuracy: 0.9347 - lr: 0.0010\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 63/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.5338 - accuracy: 0.8393 - top-5-accuracy: 0.9789 - val_loss: 0.8227 - val_accuracy: 0.8042 - val_top-5-accuracy: 0.9484 - lr: 0.0010\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 64/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.5579 - accuracy: 0.8375 - top-5-accuracy: 0.9768 - val_loss: 0.8213 - val_accuracy: 0.8011 - val_top-5-accuracy: 0.9368 - lr: 0.0010\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 65/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.4894 - accuracy: 0.8509 - top-5-accuracy: 0.9832 - val_loss: 0.8570 - val_accuracy: 0.7884 - val_top-5-accuracy: 0.9379 - lr: 0.0010\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 66/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.6124 - accuracy: 0.8267 - top-5-accuracy: 0.9726 - val_loss: 0.8375 - val_accuracy: 0.7937 - val_top-5-accuracy: 0.9442 - lr: 0.0010\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 67/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.4866 - accuracy: 0.8526 - top-5-accuracy: 0.9832 - val_loss: 0.8680 - val_accuracy: 0.8042 - val_top-5-accuracy: 0.9337 - lr: 0.0010\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 68/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.6392 - accuracy: 0.8077 - top-5-accuracy: 0.9702 - val_loss: 0.8049 - val_accuracy: 0.8011 - val_top-5-accuracy: 0.9389 - lr: 0.0010\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 69/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.5043 - accuracy: 0.8495 - top-5-accuracy: 0.9832 - val_loss: 0.8048 - val_accuracy: 0.8189 - val_top-5-accuracy: 0.9389 - lr: 0.0010\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 70/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.4817 - accuracy: 0.8540 - top-5-accuracy: 0.9821 - val_loss: 0.7751 - val_accuracy: 0.8221 - val_top-5-accuracy: 0.9474 - lr: 0.0010\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 71/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.4350 - accuracy: 0.8719 - top-5-accuracy: 0.9863 - val_loss: 0.8694 - val_accuracy: 0.8095 - val_top-5-accuracy: 0.9379 - lr: 0.0010\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 72/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.4234 - accuracy: 0.8758 - top-5-accuracy: 0.9867 - val_loss: 0.7676 - val_accuracy: 0.8095 - val_top-5-accuracy: 0.9432 - lr: 0.0010\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 73/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.4472 - accuracy: 0.8635 - top-5-accuracy: 0.9842 - val_loss: 0.8146 - val_accuracy: 0.8042 - val_top-5-accuracy: 0.9368 - lr: 0.0010\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 74/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.4509 - accuracy: 0.8702 - top-5-accuracy: 0.9849 - val_loss: 0.7839 - val_accuracy: 0.8179 - val_top-5-accuracy: 0.9421 - lr: 0.0010\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 75/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.4218 - accuracy: 0.8814 - top-5-accuracy: 0.9860 - val_loss: 0.8055 - val_accuracy: 0.8105 - val_top-5-accuracy: 0.9400 - lr: 0.0010\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 76/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.4164 - accuracy: 0.8842 - top-5-accuracy: 0.9849 - val_loss: 0.7754 - val_accuracy: 0.8179 - val_top-5-accuracy: 0.9411 - lr: 0.0010\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 77/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.3679 - accuracy: 0.8979 - top-5-accuracy: 0.9874 - val_loss: 0.8091 - val_accuracy: 0.8253 - val_top-5-accuracy: 0.9421 - lr: 0.0010\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 78/150\n",
            "90/90 [==============================] - 17s 188ms/step - loss: 0.3609 - accuracy: 0.8965 - top-5-accuracy: 0.9853 - val_loss: 0.7521 - val_accuracy: 0.8358 - val_top-5-accuracy: 0.9453 - lr: 0.0010\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 79/150\n",
            "90/90 [==============================] - 17s 187ms/step - loss: 0.4067 - accuracy: 0.8811 - top-5-accuracy: 0.9888 - val_loss: 0.7819 - val_accuracy: 0.8242 - val_top-5-accuracy: 0.9400 - lr: 0.0010\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 80/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.3866 - accuracy: 0.8789 - top-5-accuracy: 0.9944 - val_loss: 0.7640 - val_accuracy: 0.8284 - val_top-5-accuracy: 0.9411 - lr: 0.0010\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 81/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.4041 - accuracy: 0.8821 - top-5-accuracy: 0.9909 - val_loss: 0.8330 - val_accuracy: 0.8074 - val_top-5-accuracy: 0.9453 - lr: 0.0010\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 82/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.3848 - accuracy: 0.8884 - top-5-accuracy: 0.9895 - val_loss: 0.7433 - val_accuracy: 0.8400 - val_top-5-accuracy: 0.9453 - lr: 0.0010\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 83/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 0.3561 - accuracy: 0.8972 - top-5-accuracy: 0.9926 - val_loss: 0.7553 - val_accuracy: 0.8295 - val_top-5-accuracy: 0.9421 - lr: 0.0010\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 84/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.3296 - accuracy: 0.9028 - top-5-accuracy: 0.9919 - val_loss: 0.7660 - val_accuracy: 0.8253 - val_top-5-accuracy: 0.9379 - lr: 0.0010\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 85/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.3704 - accuracy: 0.8951 - top-5-accuracy: 0.9888 - val_loss: 0.7482 - val_accuracy: 0.8368 - val_top-5-accuracy: 0.9453 - lr: 0.0010\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 86/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.3939 - accuracy: 0.8818 - top-5-accuracy: 0.9888 - val_loss: 0.7254 - val_accuracy: 0.8421 - val_top-5-accuracy: 0.9484 - lr: 0.0010\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 87/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.3686 - accuracy: 0.8905 - top-5-accuracy: 0.9898 - val_loss: 0.7018 - val_accuracy: 0.8442 - val_top-5-accuracy: 0.9411 - lr: 0.0010\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 88/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.4262 - accuracy: 0.8705 - top-5-accuracy: 0.9867 - val_loss: 0.6933 - val_accuracy: 0.8368 - val_top-5-accuracy: 0.9463 - lr: 0.0010\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 89/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.3666 - accuracy: 0.8884 - top-5-accuracy: 0.9874 - val_loss: 0.8077 - val_accuracy: 0.8326 - val_top-5-accuracy: 0.9453 - lr: 0.0010\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 90/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.3171 - accuracy: 0.9049 - top-5-accuracy: 0.9930 - val_loss: 0.7312 - val_accuracy: 0.8389 - val_top-5-accuracy: 0.9484 - lr: 0.0010\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 91/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.3269 - accuracy: 0.9042 - top-5-accuracy: 0.9916 - val_loss: 0.8016 - val_accuracy: 0.8389 - val_top-5-accuracy: 0.9453 - lr: 0.0010\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 92/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.3219 - accuracy: 0.9070 - top-5-accuracy: 0.9916 - val_loss: 0.7638 - val_accuracy: 0.8411 - val_top-5-accuracy: 0.9347 - lr: 0.0010\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 93/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.3054 - accuracy: 0.9105 - top-5-accuracy: 0.9909 - val_loss: 0.7186 - val_accuracy: 0.8516 - val_top-5-accuracy: 0.9453 - lr: 0.0010\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 94/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.3426 - accuracy: 0.8965 - top-5-accuracy: 0.9902 - val_loss: 0.7770 - val_accuracy: 0.8379 - val_top-5-accuracy: 0.9379 - lr: 0.0010\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 95/150\n",
            "90/90 [==============================] - 17s 195ms/step - loss: 0.3150 - accuracy: 0.9133 - top-5-accuracy: 0.9923 - val_loss: 0.6956 - val_accuracy: 0.8516 - val_top-5-accuracy: 0.9463 - lr: 0.0010\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 96/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 0.4217 - accuracy: 0.8811 - top-5-accuracy: 0.9860 - val_loss: 0.7479 - val_accuracy: 0.8326 - val_top-5-accuracy: 0.9421 - lr: 0.0010\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 97/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 0.3898 - accuracy: 0.8804 - top-5-accuracy: 0.9877 - val_loss: 0.7276 - val_accuracy: 0.8442 - val_top-5-accuracy: 0.9453 - lr: 0.0010\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 98/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.3430 - accuracy: 0.9007 - top-5-accuracy: 0.9916 - val_loss: 0.7392 - val_accuracy: 0.8400 - val_top-5-accuracy: 0.9411 - lr: 0.0010\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 99/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.2988 - accuracy: 0.9151 - top-5-accuracy: 0.9916 - val_loss: 0.8015 - val_accuracy: 0.8316 - val_top-5-accuracy: 0.9400 - lr: 0.0010\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 100/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.3291 - accuracy: 0.9053 - top-5-accuracy: 0.9923 - val_loss: 0.6444 - val_accuracy: 0.8558 - val_top-5-accuracy: 0.9632 - lr: 0.0010\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 101/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.2040 - accuracy: 0.9439 - top-5-accuracy: 0.9947 - val_loss: 0.5860 - val_accuracy: 0.8663 - val_top-5-accuracy: 0.9621 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 102/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1898 - accuracy: 0.9453 - top-5-accuracy: 0.9951 - val_loss: 0.5717 - val_accuracy: 0.8705 - val_top-5-accuracy: 0.9579 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 103/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1728 - accuracy: 0.9537 - top-5-accuracy: 0.9958 - val_loss: 0.5607 - val_accuracy: 0.8726 - val_top-5-accuracy: 0.9589 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 104/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1673 - accuracy: 0.9540 - top-5-accuracy: 0.9975 - val_loss: 0.5508 - val_accuracy: 0.8726 - val_top-5-accuracy: 0.9579 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 105/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1794 - accuracy: 0.9505 - top-5-accuracy: 0.9961 - val_loss: 0.5456 - val_accuracy: 0.8779 - val_top-5-accuracy: 0.9568 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 106/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1597 - accuracy: 0.9589 - top-5-accuracy: 0.9965 - val_loss: 0.5383 - val_accuracy: 0.8800 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 107/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1480 - accuracy: 0.9625 - top-5-accuracy: 0.9982 - val_loss: 0.5380 - val_accuracy: 0.8768 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 108/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1785 - accuracy: 0.9554 - top-5-accuracy: 0.9961 - val_loss: 0.5256 - val_accuracy: 0.8811 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 109/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1521 - accuracy: 0.9600 - top-5-accuracy: 0.9965 - val_loss: 0.5415 - val_accuracy: 0.8747 - val_top-5-accuracy: 0.9547 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 110/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1504 - accuracy: 0.9614 - top-5-accuracy: 0.9986 - val_loss: 0.5264 - val_accuracy: 0.8832 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 111/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1427 - accuracy: 0.9653 - top-5-accuracy: 0.9972 - val_loss: 0.5296 - val_accuracy: 0.8853 - val_top-5-accuracy: 0.9568 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 112/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1566 - accuracy: 0.9593 - top-5-accuracy: 0.9979 - val_loss: 0.5237 - val_accuracy: 0.8842 - val_top-5-accuracy: 0.9516 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 113/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1449 - accuracy: 0.9646 - top-5-accuracy: 0.9986 - val_loss: 0.5215 - val_accuracy: 0.8853 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 114/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1337 - accuracy: 0.9667 - top-5-accuracy: 0.9989 - val_loss: 0.5160 - val_accuracy: 0.8853 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 115/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1342 - accuracy: 0.9646 - top-5-accuracy: 0.9982 - val_loss: 0.5099 - val_accuracy: 0.8853 - val_top-5-accuracy: 0.9568 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 116/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1415 - accuracy: 0.9649 - top-5-accuracy: 0.9965 - val_loss: 0.5167 - val_accuracy: 0.8895 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 117/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1309 - accuracy: 0.9723 - top-5-accuracy: 0.9979 - val_loss: 0.5110 - val_accuracy: 0.8916 - val_top-5-accuracy: 0.9568 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 118/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1274 - accuracy: 0.9709 - top-5-accuracy: 0.9979 - val_loss: 0.5084 - val_accuracy: 0.8916 - val_top-5-accuracy: 0.9579 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 119/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1373 - accuracy: 0.9621 - top-5-accuracy: 0.9993 - val_loss: 0.4997 - val_accuracy: 0.8916 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 120/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1297 - accuracy: 0.9702 - top-5-accuracy: 0.9975 - val_loss: 0.5012 - val_accuracy: 0.8937 - val_top-5-accuracy: 0.9547 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 121/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1247 - accuracy: 0.9705 - top-5-accuracy: 0.9982 - val_loss: 0.4908 - val_accuracy: 0.8947 - val_top-5-accuracy: 0.9579 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 122/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1233 - accuracy: 0.9705 - top-5-accuracy: 0.9989 - val_loss: 0.4969 - val_accuracy: 0.8968 - val_top-5-accuracy: 0.9568 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 123/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1202 - accuracy: 0.9705 - top-5-accuracy: 0.9975 - val_loss: 0.5013 - val_accuracy: 0.8926 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 124/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1310 - accuracy: 0.9677 - top-5-accuracy: 0.9972 - val_loss: 0.5046 - val_accuracy: 0.8895 - val_top-5-accuracy: 0.9526 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 125/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1121 - accuracy: 0.9723 - top-5-accuracy: 0.9996 - val_loss: 0.5110 - val_accuracy: 0.8905 - val_top-5-accuracy: 0.9579 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 126/150\n",
            "90/90 [==============================] - 17s 192ms/step - loss: 0.1164 - accuracy: 0.9754 - top-5-accuracy: 0.9986 - val_loss: 0.5240 - val_accuracy: 0.8832 - val_top-5-accuracy: 0.9547 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 127/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1099 - accuracy: 0.9730 - top-5-accuracy: 0.9986 - val_loss: 0.5239 - val_accuracy: 0.8926 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 128/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1162 - accuracy: 0.9705 - top-5-accuracy: 0.9975 - val_loss: 0.5195 - val_accuracy: 0.8926 - val_top-5-accuracy: 0.9579 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 129/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1168 - accuracy: 0.9705 - top-5-accuracy: 0.9982 - val_loss: 0.5206 - val_accuracy: 0.8874 - val_top-5-accuracy: 0.9589 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 130/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.1136 - accuracy: 0.9747 - top-5-accuracy: 0.9979 - val_loss: 0.5189 - val_accuracy: 0.8895 - val_top-5-accuracy: 0.9547 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 131/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1163 - accuracy: 0.9719 - top-5-accuracy: 0.9986 - val_loss: 0.5151 - val_accuracy: 0.8905 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 132/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1091 - accuracy: 0.9754 - top-5-accuracy: 0.9975 - val_loss: 0.5376 - val_accuracy: 0.8811 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 133/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1057 - accuracy: 0.9768 - top-5-accuracy: 0.9982 - val_loss: 0.5403 - val_accuracy: 0.8916 - val_top-5-accuracy: 0.9547 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 134/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.1360 - accuracy: 0.9656 - top-5-accuracy: 0.9972 - val_loss: 0.5397 - val_accuracy: 0.8926 - val_top-5-accuracy: 0.9526 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 135/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1090 - accuracy: 0.9726 - top-5-accuracy: 0.9982 - val_loss: 0.5411 - val_accuracy: 0.8863 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 136/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1159 - accuracy: 0.9733 - top-5-accuracy: 0.9982 - val_loss: 0.5301 - val_accuracy: 0.8853 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 137/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.0923 - accuracy: 0.9789 - top-5-accuracy: 0.9996 - val_loss: 0.5149 - val_accuracy: 0.8884 - val_top-5-accuracy: 0.9505 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 138/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.0941 - accuracy: 0.9796 - top-5-accuracy: 0.9979 - val_loss: 0.5146 - val_accuracy: 0.8937 - val_top-5-accuracy: 0.9547 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 139/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.0999 - accuracy: 0.9702 - top-5-accuracy: 0.9989 - val_loss: 0.5170 - val_accuracy: 0.8979 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 140/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.0937 - accuracy: 0.9786 - top-5-accuracy: 0.9989 - val_loss: 0.5230 - val_accuracy: 0.8958 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 141/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.0973 - accuracy: 0.9782 - top-5-accuracy: 0.9996 - val_loss: 0.5206 - val_accuracy: 0.8895 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 142/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1092 - accuracy: 0.9723 - top-5-accuracy: 0.9975 - val_loss: 0.5251 - val_accuracy: 0.8905 - val_top-5-accuracy: 0.9568 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 143/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.0865 - accuracy: 0.9793 - top-5-accuracy: 0.9993 - val_loss: 0.5628 - val_accuracy: 0.8842 - val_top-5-accuracy: 0.9505 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 144/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1133 - accuracy: 0.9712 - top-5-accuracy: 0.9972 - val_loss: 0.5165 - val_accuracy: 0.8895 - val_top-5-accuracy: 0.9558 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 145/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.0980 - accuracy: 0.9754 - top-5-accuracy: 0.9986 - val_loss: 0.5251 - val_accuracy: 0.8916 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 146/150\n",
            "90/90 [==============================] - 17s 189ms/step - loss: 0.0993 - accuracy: 0.9733 - top-5-accuracy: 0.9989 - val_loss: 0.5344 - val_accuracy: 0.8842 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 147/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1110 - accuracy: 0.9740 - top-5-accuracy: 0.9982 - val_loss: 0.5423 - val_accuracy: 0.8874 - val_top-5-accuracy: 0.9516 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 148/150\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 0.1019 - accuracy: 0.9754 - top-5-accuracy: 0.9982 - val_loss: 0.5355 - val_accuracy: 0.8916 - val_top-5-accuracy: 0.9495 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 149/150\n",
            "90/90 [==============================] - 17s 191ms/step - loss: 0.0908 - accuracy: 0.9789 - top-5-accuracy: 0.9989 - val_loss: 0.5398 - val_accuracy: 0.8895 - val_top-5-accuracy: 0.9537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 150/150\n",
            "90/90 [==============================] - 18s 195ms/step - loss: 0.1028 - accuracy: 0.9733 - top-5-accuracy: 0.9989 - val_loss: 0.5291 - val_accuracy: 0.8905 - val_top-5-accuracy: 0.9579 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with the Shifted Patch Tokenization and\n",
        "# Locality Self Attention modified ViT\n",
        "vit_fuse = create_vit_fused_classifier_test(vanilla=False)\n",
        "history_fuse = run_fuse_experiment(vit_fuse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "6K0e3ztvHYj9",
        "outputId": "c35b58ef-a94f-4267-f805-4443a57cbe09",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# model loss\n",
        "loss='categorical_crossentropy'\n",
        "metrics=['accuracy']\n",
        "\n",
        "plt.plot(history_fuse.history['loss'])\n",
        "plt.plot(history_fuse.history['val_loss'])\n",
        "plt.title('Model loss : ' + loss)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='best')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# model accuracy metric\n",
        "\n",
        "plt.plot(np.array(history_fuse.history[metrics[0]]))\n",
        "plt.plot(np.array(history_fuse.history['val_' + metrics[0]]))\n",
        "plt.title('Model accuracy metric : ' + metrics[0])\n",
        "plt.ylabel('Accuracy metric')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='best')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1IiEuVZHaNC",
        "outputId": "a80b4a72-47ca-4568-b23d-9b4e9f1605ba",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 3s 101ms/step - loss: 0.5590 - accuracy: 0.8916 - top-5-accuracy: 0.9632\n",
            "Test accuracy: 89.16%\n",
            "Test top 5 accuracy: 96.32%\n"
          ]
        }
      ],
      "source": [
        "test_model_ViT = True\n",
        "\n",
        "if test_model_ViT:  \n",
        "  _, accuracy, top_5_accuracy = vit_fuse.evaluate([x_test_img,x_test_audio], y_test_fuse, batch_size=BATCH_SIZE)\n",
        "  print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "  print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ahudAL4ZQzAb"
      ],
      "name": "Week3_crossattention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
